{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1023a82",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This Jupyter notebook demonstrates how to use LangChain to interact with OpenAI's API for natural language processing tasks. The notebook covers direct API calls to OpenAI and using LangChain for prompts, models, and output parsers. It provides examples and detailed instructions for setting up and using these tools effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a587c",
   "metadata": {},
   "source": [
    "## Outline\n",
    "Direct API calls to OpenAI  \n",
    "API calls through LangChain:  \n",
    "Prompts  \n",
    "Models  \n",
    "Output parsers  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ff606",
   "metadata": {},
   "source": [
    "### Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458f61c",
   "metadata": {},
   "source": [
    "Setup\n",
    "Ensure you have the required packages installed:\n",
    "```py\n",
    "%pip install python-dotenv\n",
    "%pip install openai\n",
    "%pip install pydantic==1.10.8\n",
    "%pip install rich\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4aacb1",
   "metadata": {},
   "source": [
    "### Code Examples\n",
    "\n",
    "#### Setting Up OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e267e",
   "metadata": {},
   "source": [
    "**Note** Ensure you have the required packages installed:\n",
    "```py\n",
    "%pip install pydantic==1.10.8\n",
    "%pip install rich\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8429597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from rich library that helps to improve the readability of nested dictionary outputs\n",
    "from rich import print\n",
    "from rich.pretty import Pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a64299",
   "metadata": {},
   "source": [
    "### Handling Model Deprecation\n",
    "To handle the deprecation of LLM models, we use the current date to select the appropriate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336d784-65c2-4a11-8489-b445b1fad177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f08a90",
   "metadata": {},
   "source": [
    "The original below code has been descrapted. \n",
    "```py\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "get_completion(\"What is 1+1?\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b138a7",
   "metadata": {},
   "source": [
    "### Direct API Calls to OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab7b49",
   "metadata": {},
   "source": [
    "- Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4dcf6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hello! How are you doing today?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hello! How are you doing today?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()  # Create a client instance\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92adde78",
   "metadata": {},
   "source": [
    "- Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891d2a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> equals <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m+\u001b[1;36m1\u001b[0m equals \u001b[1;36m2\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Calling the function\n",
    "result = get_completion(\"What is 1+1?\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49820e",
   "metadata": {},
   "source": [
    "### Using LangChain\n",
    "\n",
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b32b57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c34459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea0bec",
   "metadata": {},
   "source": [
    "- Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b558e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Translate the text that is delimited by triple backticks \n",
       "into a style that is American English in a calm and respectful tone\n",
       ".\n",
       "text: ```\n",
       "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters \n",
       "worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
       "```\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Translate the text that is delimited by triple backticks \n",
       "into a style that is American English in a calm and respectful tone\n",
       ".\n",
       "text: ```\n",
       "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters \n",
       "worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
       "```\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c883dcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b33f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ah, I'm really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80482d1",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a525b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c5b27",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d4a269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0c8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "#chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "#chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abec55",
   "metadata": {},
   "source": [
    "Let's follow the above instructions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bfa8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a844ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d07256",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57bda7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a31f246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac2cb16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc5566c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cf7f4",
   "metadata": {},
   "source": [
    "- Formatting Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbd51a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48989d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff3954f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c09d8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'list'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'list'\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'langchain_core.messages.human.HumanMessage'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'langchain_core.messages.human.HumanMessage'\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02dafa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Translate the text that is delimited by triple backticks into a style that is American English in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">yer help right now, matey!\\n```\\n\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\"Translate\u001b[0m\u001b[32m the text that is delimited by triple backticks into a style that is American English in a \u001b[0m\n",
       "\u001b[32mcalm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen \u001b[0m\n",
       "\u001b[32mwalls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need\u001b[0m\n",
       "\u001b[32myer help right now, matey!\\n```\\n\"\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8bbd5",
   "metadata": {},
   "source": [
    "- Calling the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd789f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "#customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8acf06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad294407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I'm really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make \n",
       "matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right \n",
       "now, friend.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "I'm really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make \n",
       "matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right \n",
       "now, friend.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c267e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ff72bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d9e8f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English \n",
       "Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's \n",
       "your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! \n",
       "See ya!\n",
       "```\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English \n",
       "Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's \n",
       "your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! \n",
       "See ya!\n",
       "```\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0ae5552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ahoy there, valued customer! Regrettably, the warranty be not coverin' the costs o' cleanin' yer galley due to yer \n",
       "own negligence. Ye see, <span style=\"color: #008000; text-decoration-color: #008000\">'twas yer own doin'</span> that ye forgot to secure the lid afore startin' the blender. 'Tis a \n",
       "tough break, indeed! Fare thee well!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ahoy there, valued customer! Regrettably, the warranty be not coverin' the costs o' cleanin' yer galley due to yer \n",
       "own negligence. Ye see, \u001b[32m'twas yer own doin'\u001b[0m that ye forgot to secure the lid afore startin' the blender. 'Tis a \n",
       "tough break, indeed! Fare thee well!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36536e79",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1ccdff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df0f4680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2386e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'For the following text, extract the following information:\\n\\ngift: Was the item </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mtemplate\u001b[0m=\u001b[32m'For the following text, extract the following information:\\n\\ngift: Was the item \u001b[0m\n",
       "\u001b[32mpurchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days \u001b[0m\n",
       "\u001b[32mdid it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any \u001b[0m\n",
       "\u001b[32msentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON \u001b[0m\n",
       "\u001b[32mwith the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "121bb0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"gift\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"delivery_days\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"price_value\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"It's slightly more expensive than the other leaf blowers out there\"</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"gift\"\u001b[0m: true,\n",
       "  \u001b[32m\"delivery_days\"\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "  \u001b[32m\"price_value\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"It's slightly more expensive than the other leaf blowers out there\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10de1d28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a3c0609",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# You will get an error by running this line of code \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# because'gift' is not a dictionary\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 'gift' is a string\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7de2b8",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2e0ec49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dea24b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b57e1ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdeaf4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1eb176c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"```json\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"```\"</span>:\n",
       "\n",
       "```json\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"gift\"</span>: string  <span style=\"color: #800080; text-decoration-color: #800080\">//</span> Was the item purchased                             as a gift for someone else?          \n",
       "Answer <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> if yes,                             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> if not or unknown.\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"delivery_days\"</span>: string  <span style=\"color: #800080; text-decoration-color: #800080\">//</span> How many days                                      did it take for the product \n",
       "to arrive? If this                                       information is not found,                                 \n",
       "output <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>.\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"price_value\"</span>: string  <span style=\"color: #800080; text-decoration-color: #800080\">//</span> Extract any                                    sentences about the value or      \n",
       "price, and output them as a                                     comma separated Python list.\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \n",
       "\u001b[32m\"```json\"\u001b[0m and \u001b[32m\"```\"\u001b[0m:\n",
       "\n",
       "```json\n",
       "\u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"gift\"\u001b[0m: string  \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Was the item purchased                             as a gift for someone else?          \n",
       "Answer \u001b[3;92mTrue\u001b[0m if yes,                             \u001b[3;91mFalse\u001b[0m if not or unknown.\n",
       "        \u001b[32m\"delivery_days\"\u001b[0m: string  \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m How many days                                      did it take for the product \n",
       "to arrive? If this                                       information is not found,                                 \n",
       "output \u001b[1;36m-1\u001b[0m.\n",
       "        \u001b[32m\"price_value\"\u001b[0m: string  \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Extract any                                    sentences about the value or      \n",
       "price, and output them as a                                     comma separated Python list.\n",
       "\u001b[1m}\u001b[0m\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "082947fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f1537a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For the following text, extract the following information:\n",
       "\n",
       "gift: Was the item purchased as a gift for someone else? Answer <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> if yes, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> if not or unknown.\n",
       "\n",
       "delivery_days: How many days did it take for the productto arrive? If this information is not found, output <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>.\n",
       "\n",
       "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
       "\n",
       "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and \n",
       "tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much \n",
       "she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the\n",
       "leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it \n",
       "for the extra features.\n",
       "\n",
       "\n",
       "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"```json\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"```\"</span>:\n",
       "\n",
       "```json\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"gift\"</span>: string  <span style=\"color: #800080; text-decoration-color: #800080\">//</span> Was the item purchased                             as a gift for someone else?          \n",
       "Answer <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> if yes,                             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> if not or unknown.\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"delivery_days\"</span>: string  <span style=\"color: #800080; text-decoration-color: #800080\">//</span> How many days                                      did it take for the product \n",
       "to arrive? If this                                       information is not found,                                 \n",
       "output <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>.\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"price_value\"</span>: string  <span style=\"color: #800080; text-decoration-color: #800080\">//</span> Extract any                                    sentences about the value or      \n",
       "price, and output them as a                                     comma separated Python list.\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For the following text, extract the following information:\n",
       "\n",
       "gift: Was the item purchased as a gift for someone else? Answer \u001b[3;92mTrue\u001b[0m if yes, \u001b[3;91mFalse\u001b[0m if not or unknown.\n",
       "\n",
       "delivery_days: How many days did it take for the productto arrive? If this information is not found, output \u001b[1;36m-1\u001b[0m.\n",
       "\n",
       "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
       "\n",
       "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and \n",
       "tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much \n",
       "she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the\n",
       "leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it \n",
       "for the extra features.\n",
       "\n",
       "\n",
       "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \n",
       "\u001b[32m\"```json\"\u001b[0m and \u001b[32m\"```\"\u001b[0m:\n",
       "\n",
       "```json\n",
       "\u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"gift\"\u001b[0m: string  \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Was the item purchased                             as a gift for someone else?          \n",
       "Answer \u001b[3;92mTrue\u001b[0m if yes,                             \u001b[3;91mFalse\u001b[0m if not or unknown.\n",
       "        \u001b[32m\"delivery_days\"\u001b[0m: string  \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m How many days                                      did it take for the product \n",
       "to arrive? If this                                       information is not found,                                 \n",
       "output \u001b[1;36m-1\u001b[0m.\n",
       "        \u001b[32m\"price_value\"\u001b[0m: string  \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Extract any                                    sentences about the value or      \n",
       "price, and output them as a                                     comma separated Python list.\n",
       "\u001b[1m}\u001b[0m\n",
       "```\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b663657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8c3a9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```json\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"gift\"</span>: true,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"delivery_days\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"price_value\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">it for the extra features.\"</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```json\n",
       "\u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"gift\"\u001b[0m: true,\n",
       "        \u001b[32m\"delivery_days\"\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "        \u001b[32m\"price_value\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth\u001b[0m\n",
       "\u001b[32mit for the extra features.\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "904f1c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d48b647a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': 2,\n",
       " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4346150f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a833fcea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
