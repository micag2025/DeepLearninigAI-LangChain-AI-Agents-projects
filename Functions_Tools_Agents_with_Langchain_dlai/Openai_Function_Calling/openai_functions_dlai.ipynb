{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3df44d6-62d0-4324-8052-419503a6b040",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling ‚úÖ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23297775",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to use `OpenAI's API for function calling with the GPT-3.5-Turbo model`. We'll cover updating the code to use the new API and provide an example function for fetching current weather information.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- OpenAI has announced the release of an updated GPT-3.5-Turbo model and the deprecation of the `gpt-3.5-turbo-0613` model.\n",
    "- The `openai.ChatCompletion.create` has been removed in OpenAI's Python client version 1.0.0 and later. The API has changed, requiring code updates to use the new format such as `client.chat.completions.create`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cabdf1",
   "metadata": {},
   "source": [
    "## Code Examples\n",
    "\n",
    "### Set up OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Print OpenAI API key (masked)\n",
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')[:5]}*****\")\n",
    "\n",
    "# Print OpenAI API key\n",
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ef5f9",
   "metadata": {},
   "source": [
    "### Example: Getting Current Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf3bd3",
   "metadata": {},
   "source": [
    "We will use an example of getting the current weather to demonstrate function calling. This is a good example because it involves external data that the language model can't generate on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dcffce",
   "metadata": {},
   "source": [
    "#### Define the Function for OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for OpenAI API\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990140b",
   "metadata": {},
   "source": [
    "#### Example User Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather like in Boston?\"\n",
    "        \"content\": \"What's the weather like in Amsterdam?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d9eb6",
   "metadata": {},
   "source": [
    "#### Call the ChatCompletion Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2a8926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None))], created=1738311875, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=82, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c71463",
   "metadata": {},
   "source": [
    "- Pretty-Print the Response  \n",
    "Let's format the above output in a cleaner and more readable way using `json.dumps()`. To do this, we need to convert the response to a dictionary first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f940206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311875,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "#import json\n",
    "\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d971179",
   "metadata": {},
   "source": [
    "**Explanation output** This output represents a response from OpenAI's GPT-3.5-Turbo model. The model was prompted with a message, and its response includes a function call to get_current_weather with the argument {\"location\":\"Amsterdam\"}. The response indicates that the assistant decided to call the function instead of generating text content. The response includes metadata such as the model used, creation time, and token usage details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f994411c",
   "metadata": {},
   "source": [
    "#### Access the Message Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205c434",
   "metadata": {},
   "source": [
    "To access response as an object, we need to use `dot notation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a700da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Extract the content from the response\n",
    "response_message = response.choices[0].message\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74c69a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311875,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert response object to dictionary\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05b577",
   "metadata": {},
   "source": [
    "**Explanation output** This output is from an OpenAI GPT-3.5-Turbo model, indicating that it received a prompt and decided to make a function call. The specific function called is get_current_weather with the argument {\"location\":\"Amsterdam\"}. The response includes metadata such as the response ID, the model used, creation time, token usage, and details about the function call. The message generated by the assistant does not contain direct content but initiates a function call to gather the required information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38607e5",
   "metadata": {},
   "source": [
    "- Access the Message Content  \n",
    "`response_message[\"content\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3db94496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Extract the content from the response\n",
    "response_message = response.choices[0].message\n",
    "content = response_message.content  # Use dot notation\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073b1f3",
   "metadata": {},
   "source": [
    "#### Handling Function Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6441fd",
   "metadata": {},
   "source": [
    "- Handling Function Calls\n",
    "If the response contains a function call (as seen in the original output), content will be None, and you should `access the function details` instead:\n",
    "`response_message[\"function_call\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65638e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: get_current_weather\n",
      "Arguments: {\"location\":\"Amsterdam\"}\n"
     ]
    }
   ],
   "source": [
    "if response_message.function_call:\n",
    "    function_name = response_message.function_call.name\n",
    "    function_args = response_message.function_call.arguments\n",
    "    print(f\"Function Name: {function_name}\")\n",
    "    print(f\"Arguments: {function_args}\")\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692a21e",
   "metadata": {},
   "source": [
    "#### Convert Response Object to a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6ade065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"audio\": null,\n",
      "    \"function_call\": {\n",
      "        \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "        \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"tool_calls\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert response object to a dictionary\n",
    "response_dict = response_message.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ca765",
   "metadata": {},
   "source": [
    "**Explanation output** This output represents part of a response from an AI assistant (role: \"assistant\") indicating that it has chosen to call a function rather than generate direct content. The function being called is `get_current_weather` with the argument `{\"location\":\"Amsterdam\"}`. The fields `content, refusal, audio, and tool_calls` are null, indicating that no textual content, refusal message, audio response, or tool calls were included in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f0d1647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Amsterdam'}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "# Access function call details using dot notation\n",
    "arguments_json = response_message.function_call.arguments  # This is already a string\n",
    "\n",
    "# Parse JSON string into a Python dictionary\n",
    "arguments_dict = json.loads(arguments_json)\n",
    "\n",
    "print(arguments_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "675d9372-4388-4f18-b44c-e291668ea46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d311",
   "metadata": {},
   "source": [
    "* Pass a message that is not related to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d4346bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgdOSFWGeXAOsU5lKhB25BdhjPIJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311946, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=76, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b27cebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgdOSFWGeXAOsU5lKhB25BdhjPIJ\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311946,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 11,\n",
      "        \"prompt_tokens\": 76,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aae46",
   "metadata": {},
   "source": [
    "* Pass additional parameters to force the model to use or not a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6e86d",
   "metadata": {},
   "source": [
    "#### Pass a Message Not Related to a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17edba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgdcXz7QjB0TwqBdNhLGgbgdYYRF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311960, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=76, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "123f1cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgdcXz7QjB0TwqBdNhLGgbgdYYRF\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311960,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 11,\n",
      "        \"prompt_tokens\": 76,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284088e9",
   "metadata": {},
   "source": [
    "* Use mode 'none' for function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867dccb9",
   "metadata": {},
   "source": [
    "#### Call the ChatCompletion Endpoint for Non-Function Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cde66343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Avgdo3xdNARN2uzWJPKb7mNNmEpFE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311972, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=77, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19c931ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-Avgdo3xdNARN2uzWJPKb7mNNmEpFE\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311972,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 10,\n",
      "        \"prompt_tokens\": 77,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05a76e",
   "metadata": {},
   "source": [
    "* When the message should call a function and still uses mode 'none'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40311744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Avge0TYjc5gMaAKC9xz9cLTiqN08c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sure, let me check that for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311984, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=82, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather in Boston?\",\n",
    "        \"content\": \"What's the weather in Amsterdam?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32ecc17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-Avge0TYjc5gMaAKC9xz9cLTiqN08c\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Sure, let me check that for you.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311984,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 10,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 92,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38735d9f",
   "metadata": {},
   "source": [
    "* Force calling a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24e0749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgeHUKUjGs62bMDLr22UzID8tUze', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"San Francisco, CA\"}', name='get_current_weather'), tool_calls=None))], created=1738312001, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=86, total_tokens=95, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36d75289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgeHUKUjGs62bMDLr22UzID8tUze\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312001,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 9,\n",
      "        \"prompt_tokens\": 86,\n",
      "        \"total_tokens\": 95,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27abbdc",
   "metadata": {},
   "source": [
    "* Final notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3062eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgeewkQWYL0xyG020vrnV99jSDsV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None))], created=1738312024, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=92, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather like in Boston!\",\n",
    "        \"content\": \"What's the weather like in Amsterdam!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a5d1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgeewkQWYL0xyG020vrnV99jSDsV\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312024,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 92,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc2e1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content from the response\n",
    "messages.append(response.choices[0].message)  # ‚úÖ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "579cc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response.choices[0].message.function_call.arguments)  # ‚úÖ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94886508",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = get_current_weather(args)  # Assuming `get_current_weather` is properly defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa1e07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    args = json.loads(response_message.function_call.arguments)  # Convert JSON string to dictionary\n",
    "    observation = get_current_weather(args)  # Call the function with extracted arguments\n",
    "    print(observation)\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f05f3",
   "metadata": {},
   "source": [
    "**Explanation output** This output represents weather information for the location \"Amsterdam.\" It includes the current temperature of 72 degrees Fahrenheit and a weather forecast indicating \"sunny\" and \"windy\" conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360f47b",
   "metadata": {},
   "source": [
    "- Final Fixed & Formatted Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5061a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Function Call Detected:\n",
      "üîπ Function Name: get_current_weather\n",
      "üîπ Arguments: {\n",
      "    \"location\": \"Amsterdam\"\n",
      "}\n",
      "\n",
      "üå¶Ô∏è Weather Observation Result:\n",
      "\"{\\\"location\\\": {\\\"location\\\": \\\"Amsterdam\\\"}, \\\"temperature\\\": \\\"72\\\", \\\"unit\\\": \\\"fahrenheit\\\", \\\"forecast\\\": [\\\"sunny\\\", \\\"windy\\\"]}\"\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Pretty-print the output\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")  # Pretty print JSON arguments\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))  # Assuming the function returns a dictionary\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da38562",
   "metadata": {},
   "source": [
    "If the assistant calls get_current_weather with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9dc4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Function Call Detected:\n",
      "üîπ Function Name: get_current_weather\n",
      "üîπ Arguments: {\n",
      "    \"location\": \"Amsterdam\"\n",
      "}\n",
      "\n",
      "üå¶Ô∏è Weather Observation Result:\n",
      "{\n",
      "    \"location\": {\n",
      "        \"location\": \"Amsterdam\"\n",
      "    },\n",
      "    \"temperature\": \"72\",\n",
      "    \"unit\": \"fahrenheit\",\n",
      "    \"forecast\": [\n",
      "        \"sunny\",\n",
      "        \"windy\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure `observation` is a dictionary, not a string\n",
    "    if isinstance(observation, str):\n",
    "        observation = json.loads(observation)\n",
    "\n",
    "    # Pretty-print the function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63454808-10a2-4301-9977-89aa79018152",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91f5c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# Ensure observation is a properly formatted string\n",
    "if isinstance(observation, dict):\n",
    "    observation_str = json.dumps(observation)  # Convert dictionary to JSON string\n",
    "else:\n",
    "    observation_str = observation  # If already a string, use as-is\n",
    "\n",
    "# Append the function result to the messages list\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"content\": observation_str,  # Now a properly formatted string\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57cf475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "#response = client.chat.completions.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#    messages=messages,  \n",
    "#)\n",
    "\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2664659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Assistant Response:\n",
      "I'm sorry, but I don't have real-time information on the current weather. You can check the weather in Boston by using a weather website or app like Weather.com or AccuWeather.\n",
      "\n",
      "üîµ Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvgfXUxC1BEPnPUCFpU9Sz7lsoj9T\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"I don't have real-time information, but you can check the current weather in Boston by visiting a weather website or using a weather app on your phone.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312079,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 32,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 57,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import openai\n",
    "#import json\n",
    "\n",
    "# Initialize OpenAI client (replace with your actual API key)\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Existing messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Amsterdam?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API to get response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)  # Convert dict to JSON string\n",
    "    else:\n",
    "        observation_str = str(observation)  # Ensure it's a string\n",
    "\n",
    "    # Append the function result back to the conversation history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,  # ‚úÖ Now always a string\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Convert observation back to a dictionary if needed for pretty-printing\n",
    "    if isinstance(observation_str, str):\n",
    "        observation = json.loads(observation_str)\n",
    "\n",
    "    # Print formatted weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nüîµ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388276b",
   "metadata": {},
   "source": [
    "**Explantion output** The issue is that the assistant is not calling the function (get_current_weather). Instead, it is giving a default response, `saying it does not have real-time information`.\n",
    "üîπ Why Is This Happening?  \n",
    "- The assistant isn‚Äôt aware that it can call a function.  \n",
    "- You need to explicitly define functions in your request to OpenAI.  \n",
    "- No function definition was provided to OpenAI's API.  \n",
    "- You must include functions in client.chat.completions.create().  \n",
    "- function_call behavior isn‚Äôt specified.  \n",
    "- OpenAI won‚Äôt automatically call a function unless you tell it to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36d780",
   "metadata": {},
   "source": [
    "#### ‚úÖ Final Fixed & Optimized Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17143c1d",
   "metadata": {},
   "source": [
    "Let's fix the above code in order to get a significan response from the assistent. Thus, in this case, get an answer about the actual weather in Amsterdam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2544bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Function Call Detected:\n",
      "üîπ Function Name: get_current_weather\n",
      "üîπ Arguments: {\n",
      "    \"location\": \"Amsterdam\",\n",
      "    \"unit\": \"celsius\"\n",
      "}\n",
      "\n",
      "üå¶Ô∏è Weather Observation Result:\n",
      "{\n",
      "    \"location\": {\n",
      "        \"location\": \"Amsterdam\",\n",
      "        \"unit\": \"celsius\"\n",
      "    },\n",
      "    \"temperature\": \"72\",\n",
      "    \"unit\": \"fahrenheit\",\n",
      "    \"forecast\": [\n",
      "        \"sunny\",\n",
      "        \"windy\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "üîµ Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvgfzNg8jGdCmelUs4f4gZHzpgoTd\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"The current weather in Amsterdam is 22\\u00b0C (72\\u00b0F) with sunny and windy conditions.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312107,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 21,\n",
      "        \"prompt_tokens\": 137,\n",
      "        \"total_tokens\": 158,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#import openai\n",
    "#import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Define the function OpenAI can call\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g., 'Boston'\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Amsterdam?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API with function definition\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # ‚úÖ Add function definition\n",
    "    function_call=\"auto\"  # ‚úÖ Force the model to call a function if needed\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)\n",
    "    else:\n",
    "        observation_str = str(observation)\n",
    "\n",
    "    # Append function response back to messages\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(json.loads(observation_str), indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages to continue the conversation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # ‚úÖ Keep functions defined for future calls\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nüîµ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122a720",
   "metadata": {},
   "source": [
    "**Explanation output** To get the message in the file OpenAI Response, please open the text edit. To sum up, now, the assistent gives the right answer, thus info about the actual weather in Amsterdam.  \n",
    "Final OpenAI Response:  \n",
    "{  \n",
    "    \"id\": \"chatcmpl-AvgfzNg8jGdCmelUs4f4gZHzpgoTd\",  \n",
    "    \"choices\": [  \n",
    "        {  \n",
    "            \"finish_reason\": \"stop\",  \n",
    "            \"index\": 0,  \n",
    "            \"logprobs\": null,  \n",
    "            `\"message\":   {\n",
    "                \"content\": \"The current weather in Amsterdam is 22\\u00b0C (72\\u00b0F) with sunny and windy`   \"conditions.\",  \n",
    "                \"refusal\": null,  \n",
    "                \"role\": \"assistant\",  \n",
    "                \"audio\": null,  \n",
    "                \"function_call\": null,  \n",
    "                \"tool_calls\": null  \n",
    "            }  \n",
    "        }  \n",
    "    ],  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad839a6-83e9-46a2-9d39-d7be8cbcc6f8",
   "metadata": {},
   "source": [
    "üîπ What‚Äôs Fixed & Optimized?  \n",
    "‚úÖ Uses dot notation instead of response[\"choices\"][0][\"message\"]  \n",
    "‚úÖ Ensures observation is properly formatted (json.dumps(observation))  \n",
    "‚úÖ Handles function calls correctly  \n",
    "‚úÖ Prints a structured, readable response  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71b4b8-3a1c-4c19-9d65-d50340207dca",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrates how to integrate OpenAI's function calling capabilities using the updated GPT-3.5-Turbo model. By following these examples, you can effectively utilize the latest OpenAI API changes in your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98ceb2-0feb-49c6-9889-70e9b52300e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
