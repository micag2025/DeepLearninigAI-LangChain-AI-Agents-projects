{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3df44d6-62d0-4324-8052-419503a6b040",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b038f2-759a-42e9-ab02-eca264b93ee5",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- OpenAI has announced the release of an updated GPT-3.5-Turbo model and the deprecation of the ```gpt-3.5-turbo-0613``` model. The gpt-3.5-turbo-0613 model, which has been utilized in this Short Course since its launch in October 2023, will be replaced by the ```gpt-3.5-turbo``` model. > Note: This notebook was updated in June 2024. Consequently, we are now using the ```gpt-3.5-turbo model``` instead of the ```gpt-3.5-turbo-0613``` model featured by the instructor in the video lesson.\n",
    "- The `openai.ChatCompletion.create` has been removed in OpenAI's Python client version 1.0.0 and later. The API has changed, and here it has been update the code to use the new format.  \n",
    "‚úÖ Solution: Update the Code to Use the New API  \n",
    "In OpenAI's latest API, `ChatCompletion.create` is replaced by `openai.ChatCompletion.create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f8d9dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-ftrE5R1SUdZBr8XxRi3rtI4F5g2i47i67FfUv9AXmjT3BlbkFJqODP02vVsRNjuVbRKIfFInuuWKeXKv_SqGGoIUNokA\n"
     ]
    }
   ],
   "source": [
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555e832",
   "metadata": {},
   "source": [
    "We will use as example `getting the current weather` because this is a good example because is something that the language model can't neccessary do it self. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather like in Boston?\"\n",
    "        \"content\": \"What's the weather like in Amsterdam?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654fce05-7ef6-49d7-8d78-f190ecf3f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ChatCompletion endpoint\n",
    "#response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "    #functions=functions\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2a8926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None))], created=1738311875, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=82, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "#import openai\n",
    "#import os\n",
    "\n",
    "# Ensure you are using the correct client initialization\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5808587",
   "metadata": {},
   "source": [
    "Let's get format of the above output in a cleaner and more readable way using json.dumps(). To do this,   we need to convert the response to a dictionary first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f940206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311875,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_message = response[\"choices\"][0][\"message\"]\n",
    "#print(response_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472da20",
   "metadata": {},
   "source": [
    "**Explanation output** The error message TypeError: 'ChatCompletion' object is not subscriptable means that response is an object, not a dictionary. To `get access response as a Object` we should `use dot notation (response.choices[0].message) instead of dictionary-style indexing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a700da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74c69a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311875,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "# Convert response object to dictionary\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38607e5",
   "metadata": {},
   "source": [
    "- Access the Message Content  \n",
    "`response_message[\"content\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3db94496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Extract the content from the response\n",
    "response_message = response.choices[0].message\n",
    "content = response_message.content  # Use dot notation\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6441fd",
   "metadata": {},
   "source": [
    "- Handling Function Calls\n",
    "If the response contains a function call (as seen in your original output), content will be None, and you should `access the function details` instead:\n",
    "`response_message[\"function_call\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65638e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: get_current_weather\n",
      "Arguments: {\"location\":\"Amsterdam\"}\n"
     ]
    }
   ],
   "source": [
    "if response_message.function_call:\n",
    "    function_name = response_message.function_call.name\n",
    "    function_args = response_message.function_call.arguments\n",
    "    print(f\"Function Name: {function_name}\")\n",
    "    print(f\"Arguments: {function_args}\")\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6ade065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"audio\": null,\n",
      "    \"function_call\": {\n",
      "        \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "        \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"tool_calls\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert response object to a dictionary\n",
    "response_dict = response_message.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b90cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "# Convert response object to a dictionary\n",
    "#response_dict = response.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "#formatted_response = json.dumps(response_dict, indent=4)\n",
    "#print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "433a51b6-9c92-4765-85aa-285dccf7748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "#args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "#get_current_weather(args)\n",
    "\n",
    "#  Use dot notation: response_message.content instead of response_message[\"content\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f0d1647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Amsterdam'}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "# Access function call details using dot notation\n",
    "arguments_json = response_message.function_call.arguments  # This is already a string\n",
    "\n",
    "# Parse JSON string into a Python dictionary\n",
    "arguments_dict = json.loads(arguments_json)\n",
    "\n",
    "print(arguments_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "675d9372-4388-4f18-b44c-e291668ea46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d311",
   "metadata": {},
   "source": [
    "* Pass a message that is not related to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8300232d-4f02-478b-bba2-d47173422866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "    #functions=functions,\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d4346bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgdOSFWGeXAOsU5lKhB25BdhjPIJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311946, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=76, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b27cebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgdOSFWGeXAOsU5lKhB25BdhjPIJ\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311946,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 11,\n",
      "        \"prompt_tokens\": 76,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aae46",
   "metadata": {},
   "source": [
    "* Pass additional parameters to force the model to use or not a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2af9f72-1cb9-4a97-b030-22562ecab99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages = [\n",
    "    #{\n",
    "        #\"role\": \"user\",\n",
    "        #\"content\": \"hi!\",\n",
    "    #}\n",
    "#]\n",
    "#response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "    #functions=functions,\n",
    "    #function_call=\"auto\",\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17edba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgdcXz7QjB0TwqBdNhLGgbgdYYRF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311960, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=76, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "123f1cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgdcXz7QjB0TwqBdNhLGgbgdYYRF\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311960,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 11,\n",
      "        \"prompt_tokens\": 76,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284088e9",
   "metadata": {},
   "source": [
    "* Use mode 'none' for function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8cafc-f785-4595-9e3c-48b06424ee8b",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cde66343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Avgdo3xdNARN2uzWJPKb7mNNmEpFE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311972, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=77, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19c931ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-Avgdo3xdNARN2uzWJPKb7mNNmEpFE\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311972,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 10,\n",
      "        \"prompt_tokens\": 77,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05a76e",
   "metadata": {},
   "source": [
    "* When the message should call a function and still uses mode 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7cc5a7-1572-4171-9016-9ec2871d389b",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in Boston?\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40311744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Avge0TYjc5gMaAKC9xz9cLTiqN08c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sure, let me check that for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311984, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=82, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather in Boston?\",\n",
    "        \"content\": \"What's the weather in Amsterdam?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32ecc17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-Avge0TYjc5gMaAKC9xz9cLTiqN08c\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Sure, let me check that for you.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311984,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 10,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 92,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38735d9f",
   "metadata": {},
   "source": [
    "* Force calling a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a92ba-5677-4c72-b556-d29e6a4152a0",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24e0749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgeHUKUjGs62bMDLr22UzID8tUze', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"San Francisco, CA\"}', name='get_current_weather'), tool_calls=None))], created=1738312001, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=86, total_tokens=95, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36d75289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgeHUKUjGs62bMDLr22UzID8tUze\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312001,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 9,\n",
      "        \"prompt_tokens\": 86,\n",
      "        \"total_tokens\": 95,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27abbdc",
   "metadata": {},
   "source": [
    "* Final notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5229a4-2700-48b4-b2b9-3b1e1535f903",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3062eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgeewkQWYL0xyG020vrnV99jSDsV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None))], created=1738312024, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=92, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather like in Boston!\",\n",
    "        \"content\": \"What's the weather like in Amsterdam!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a5d1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgeewkQWYL0xyG020vrnV99jSDsV\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312024,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 92,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc2e1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content from the response\n",
    "messages.append(response.choices[0].message)  # ‚úÖ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f3a9d7-9f30-4524-a952-5dd87c6d2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages.append(response[\"choices\"][0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c817376f-3a7f-4448-acdd-1639c70d42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = json.loads(response[\"choices\"][0][\"message\"]['function_call']['arguments'])\n",
    "#observation = get_current_weather(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "579cc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response.choices[0].message.function_call.arguments)  # ‚úÖ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94886508",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = get_current_weather(args)  # Assuming `get_current_weather` is properly defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa1e07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    args = json.loads(response_message.function_call.arguments)  # Convert JSON string to dictionary\n",
    "    observation = get_current_weather(args)  # Call the function with extracted arguments\n",
    "    print(observation)\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360f47b",
   "metadata": {},
   "source": [
    "Final Fixed & Formatted Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5061a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Function Call Detected:\n",
      "üîπ Function Name: get_current_weather\n",
      "üîπ Arguments: {\n",
      "    \"location\": \"Amsterdam\"\n",
      "}\n",
      "\n",
      "üå¶Ô∏è Weather Observation Result:\n",
      "\"{\\\"location\\\": {\\\"location\\\": \\\"Amsterdam\\\"}, \\\"temperature\\\": \\\"72\\\", \\\"unit\\\": \\\"fahrenheit\\\", \\\"forecast\\\": [\\\"sunny\\\", \\\"windy\\\"]}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Pretty-print the output\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")  # Pretty print JSON arguments\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))  # Assuming the function returns a dictionary\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da38562",
   "metadata": {},
   "source": [
    "If the assistant calls get_current_weather with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9dc4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Function Call Detected:\n",
      "üîπ Function Name: get_current_weather\n",
      "üîπ Arguments: {\n",
      "    \"location\": \"Amsterdam\"\n",
      "}\n",
      "\n",
      "üå¶Ô∏è Weather Observation Result:\n",
      "{\n",
      "    \"location\": {\n",
      "        \"location\": \"Amsterdam\"\n",
      "    },\n",
      "    \"temperature\": \"72\",\n",
      "    \"unit\": \"fahrenheit\",\n",
      "    \"forecast\": [\n",
      "        \"sunny\",\n",
      "        \"windy\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure `observation` is a dictionary, not a string\n",
    "    if isinstance(observation, str):\n",
    "        observation = json.loads(observation)\n",
    "\n",
    "    # Pretty-print the function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63454808-10a2-4301-9977-89aa79018152",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91f5c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Ensure observation is a properly formatted string\n",
    "if isinstance(observation, dict):\n",
    "    observation_str = json.dumps(observation)  # Convert dictionary to JSON string\n",
    "else:\n",
    "    observation_str = observation  # If already a string, use as-is\n",
    "\n",
    "# Append the function result to the messages list\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"content\": observation_str,  # Now a properly formatted string\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f323fb69-c907-4f19-a2d9-80d828b4a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = openai.ChatCompletion.create(\n",
    "   # model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cf475",
   "metadata": {},
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,  \n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb76cc",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "# Call the ChatCompletion endpoint\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,  \n",
    ")\n",
    "\n",
    "# Convert response to a dictionary and pretty-print it\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2664659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Assistant Response:\n",
      "I'm sorry, but I don't have real-time information on the current weather. You can check the weather in Boston by using a weather website or app like Weather.com or AccuWeather.\n",
      "\n",
      "üîµ Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvgfXUxC1BEPnPUCFpU9Sz7lsoj9T\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"I don't have real-time information, but you can check the current weather in Boston by visiting a weather website or using a weather app on your phone.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312079,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 32,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 57,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client (replace with your actual API key)\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Existing messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API to get response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)  # Convert dict to JSON string\n",
    "    else:\n",
    "        observation_str = str(observation)  # Ensure it's a string\n",
    "\n",
    "    # Append the function result back to the conversation history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,  # ‚úÖ Now always a string\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Convert observation back to a dictionary if needed for pretty-printing\n",
    "    if isinstance(observation_str, str):\n",
    "        observation = json.loads(observation_str)\n",
    "\n",
    "    # Print formatted weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nüîµ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388276b",
   "metadata": {},
   "source": [
    "**Explantion output** issue is that the assistant is not calling the function (get_current_weather). Instead, it is giving a default response, saying it does not have real-time information.\n",
    "üîπ Why Is This Happening?\n",
    "The assistant isn‚Äôt aware that it can call a function.\n",
    "You need to explicitly define functions in your request to OpenAI.\n",
    "No function definition was provided to OpenAI's API.\n",
    "You must include functions in client.chat.completions.create().\n",
    "function_call behavior isn‚Äôt specified.\n",
    "OpenAI won‚Äôt automatically call a function unless you tell it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2544bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Function Call Detected:\n",
      "üîπ Function Name: get_current_weather\n",
      "üîπ Arguments: {\n",
      "    \"location\": \"Amsterdam\",\n",
      "    \"unit\": \"celsius\"\n",
      "}\n",
      "\n",
      "üå¶Ô∏è Weather Observation Result:\n",
      "{\n",
      "    \"location\": {\n",
      "        \"location\": \"Amsterdam\",\n",
      "        \"unit\": \"celsius\"\n",
      "    },\n",
      "    \"temperature\": \"72\",\n",
      "    \"unit\": \"fahrenheit\",\n",
      "    \"forecast\": [\n",
      "        \"sunny\",\n",
      "        \"windy\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "üîµ Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvgfzNg8jGdCmelUs4f4gZHzpgoTd\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"The current weather in Amsterdam is 22\\u00b0C (72\\u00b0F) with sunny and windy conditions.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312107,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 21,\n",
      "        \"prompt_tokens\": 137,\n",
      "        \"total_tokens\": 158,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Define the function OpenAI can call\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g., 'Boston'\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Amsterdam?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API with function definition\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # ‚úÖ Add function definition\n",
    "    function_call=\"auto\"  # ‚úÖ Force the model to call a function if needed\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)\n",
    "    else:\n",
    "        observation_str = str(observation)\n",
    "\n",
    "    # Append function response back to messages\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(json.loads(observation_str), indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages to continue the conversation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # ‚úÖ Keep functions defined for future calls\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nüîµ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8cbe3b",
   "metadata": {},
   "source": [
    "‚úÖ Final Fixed & Optimized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf4bedc6-6342-4d69-9e19-181d2b0aa243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Assistant Response:\n",
      "I'm sorry, but I cannot provide real-time weather information. You can check the weather in Boston by using a weather app on your smartphone or by visiting a reliable weather website.\n",
      "\n",
      "üîµ Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvggVzh5e5abBhGkc9hQtnfOkEhp3\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"I'm sorry, but I do not have real-time information on the current weather conditions. You can check the weather in Boston by visiting a reliable weather website or using a weather app on your phone.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312139,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 41,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 66,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client (replace with your actual API key)\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Existing messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API to get response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)  # Convert dict to JSON string\n",
    "    else:\n",
    "        observation_str = observation  # If already a string, use as-is\n",
    "\n",
    "    # Append the function result back to the conversation history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nüü¢ Function Call Detected:\")\n",
    "    print(f\"üîπ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"üîπ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Convert observation back to a dictionary if needed for pretty-printing\n",
    "    if isinstance(observation_str, str):\n",
    "        observation = json.loads(observation_str)\n",
    "\n",
    "    # Print formatted weather observation\n",
    "    print(\"\\nüå¶Ô∏è Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nüí¨ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nüîµ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad839a6-83e9-46a2-9d39-d7be8cbcc6f8",
   "metadata": {},
   "source": [
    "üîπ What‚Äôs Fixed & Optimized?\n",
    "‚úÖ Uses dot notation instead of response[\"choices\"][0][\"message\"]\n",
    "‚úÖ Ensures observation is properly formatted (json.dumps(observation))\n",
    "‚úÖ Handles function calls correctly\n",
    "‚úÖ Prints a structured, readable response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71b4b8-3a1c-4c19-9d65-d50340207dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98ceb2-0feb-49c6-9889-70e9b52300e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec827289-00c7-444e-aeb2-1e7404fbc15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd3cb6-a782-427a-bd34-46ce47e5f707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef7189-688b-4d79-b11b-67b147a00352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6733b4e-a958-421c-a3c8-635e91428f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4ecd5-14c1-492e-84ec-b4f6bb508e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e262ae6-092b-4f9e-a1cc-cc1704ecfe76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc5cd3-84f4-4d05-b941-575cafd3e14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca8690-50b3-42dc-b95c-364bbcd14581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e64656-d3ee-47a5-96e0-766652f28138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27659fe-3720-4e13-83d0-fe2d52b03075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c16168-2988-4540-a921-b78e299ab5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1d9ed-fb4e-4f3f-a8df-4a6d67c3ec1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed11cb-5a90-49a5-aecb-48081d146af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f0256-9cb4-4f3b-8614-0b69a4eeaac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442de8e-ad55-4730-a43b-0c2bc2066b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854155b-57f8-49f2-b595-6b6163d9db2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8637d7d-d6cc-4c55-b3cc-8dc51a35efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a450da3-ef87-44f7-872c-39a1a714a015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd24043-91e6-4838-8ce0-7f02802cf62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63167545-4805-4534-a8c0-9e3161edc02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5a420-9c52-441c-b868-6ce69c498477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab51675-a078-4704-b63b-9f722d86b0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c2a24-c011-4c44-a78e-611143ff3034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600778a5-a4d5-44aa-b3a7-172c82e74eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60557042-93b5-4172-8aaa-1219ea35addb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f24b4-0796-4c2d-86ab-0d23766551d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611029f7-e4c5-45b0-bcc9-9ec214a32686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ed315-b80a-4d82-bda8-41cc54b30b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be374e72-c849-4962-bb50-33607824bab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7702f2-cee6-4649-a662-6d1dc9d49e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2ba14-9908-48b1-adad-1ef764114254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
