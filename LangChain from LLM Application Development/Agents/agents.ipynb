{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Agents 🤖\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will explore the use of `LangChain agents for various tasks`, including utilizing built-in tools like DuckDuckGo search and Wikipedia, as well as defining our own tools. We will cover the following topics:  \n",
    "\n",
    "- Using built-in LangChain tools  \n",
    "- Defining custom tools\n",
    "- Working with a Python agent\n",
    "- Text-to-Speech (TTS) examples\n",
    "- Creating and interacting with an SQL database using LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5795a9",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First, we need to set up our environment and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a2b5a",
   "metadata": {},
   "source": [
    "### Account for Deprecation of LLM Model  \n",
    "We will account for the deprecation of the LLM model by setting the appropriate model based on the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7269176-8094-40ce-bedc-4c6421b16e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b9ad2",
   "metadata": {},
   "source": [
    "### Built-in LangChain tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f1ac5",
   "metadata": {},
   "source": [
    "We will install the necessary packages and utilize built-in tools from LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U wikipedia\n",
    "#!pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2a8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b93d0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "#from langchain.tools.python.tool import PythonREPLTool\n",
    "#from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aadd5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_10316\\95558306.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0, model=llm_model)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM model\n",
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394924ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load tools\n",
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02cd4956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_10316\\506757835.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent= initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize agent\n",
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de15bd8",
   "metadata": {},
   "source": [
    "### Example Usage of Built-in Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b10a71",
   "metadata": {},
   "source": [
    "Here, we will use the agent to perform a simple calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44601fe4-5f24-4ff2-a5df-a7e194a5b4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_10316\\1453878245.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent(\"What is the 25% of 300?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: We can use a calculator to find 25% of 300.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"25% of 300\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: 75.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the 25% of 300?', 'output': '75.0'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a simple calculation\n",
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee3df6-ded9-4c96-ba47-a6cf636c1b9b",
   "metadata": {},
   "source": [
    "#### Wikipedia example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc96508",
   "metadata": {},
   "source": [
    "In this example, we will use Wikipedia to find information about Tom M. Mitchell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441df699-0a52-4812-a0a7-4605204f0aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use Wikipedia to find out which book Tom M. Mitchell wrote.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Tom M. Mitchell\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Tom M. Mitchell\n",
      "Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past president of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n",
      "\n",
      "\n",
      "\n",
      "Page: Ensemble learning\n",
      "Summary: In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.\n",
      "Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can use the information from the Wikipedia summary to determine the book written by Tom M. Mitchell.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Machine Learning (book)\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "Statistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning. \n",
      "From a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.\n",
      "\n",
      "Page: Outline of machine learning\n",
      "Summary: The following outline is provided as an overview of, and topical guide to, machine learning:\n",
      "Machine learning (ML) is a subfield of artificial intelligence within computer science that evolved from the study of pattern recognition and computational learning theory. In 1959, Arthur Samuel defined machine learning as a \"field of study that gives computers the ability to learn without being explicitly programmed\". ML involves the study and construction of algorithms that can learn from and make predictions on data. These algorithms operate by building a model from a training set of example observations to make data-driven predictions or decisions expressed as outputs, rather than following strictly static program instructions.\n",
      "\n",
      "\n",
      "\n",
      "Page: Timeline of machine learning\n",
      "Summary: This page is a timeline of machine learning. Major discoveries, achievements, milestones and other major events in machine learning are included.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found that Tom M. Mitchell wrote the textbook \"Machine Learning.\"\n",
      "Final Answer: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90299a00-eb79-4755-bb4b-bf61d88c7fed",
   "metadata": {},
   "source": [
    "#### Python Agent  \n",
    "We will create a Python agent to perform tasks using Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7617576-d855-4ede-9c1a-be742f1504cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05e7dc6-f07e-43df-a2f6-9a0816291861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a list of customers\n",
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f887f8f9-216e-489a-945a-f38fbccbe5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_10316\\2161092319.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(f\"\"\"Sort these customers by \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mWe can use the `sorted()` function in Python to sort the list of customers based on last name first and then first name.\n",
      "Action: Python_REPL\n",
      "Action Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n",
      "sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\n",
      "print(sorted_customers)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the customers by last name and then first name\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74466cec-2d98-438b-805f-33e31fdc3035",
   "metadata": {},
   "source": [
    "#### View detailed outputs of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12548579-810b-416e-afb5-178296685c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python_REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [1.42s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"We can use the `sorted()` function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python_REPL\\nAction Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"We can use the `sorted()` function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python_REPL\\nAction Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 101,\n",
      "                \"prompt_tokens\": 328,\n",
      "                \"total_tokens\": 429,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f4d96ce9-8437-4dcf-beb9-62c48e4e7955-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 101,\n",
      "      \"prompt_tokens\": 328,\n",
      "      \"total_tokens\": 429,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.42s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"We can use the `sorted()` function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python_REPL\\nAction Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:Python_REPL] Entering Tool run with input:\n",
      "\u001b[0m\"sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:Python_REPL] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"We can use the `sorted()` function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python_REPL\\nAction Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))\\nObservation: \\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python_REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:We can use the `sorted()` function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python_REPL\\nAction Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))\\nObservation: \\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [909ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I now know the final answer\\nFinal Answer: [['Jen', 'Ayai'], ['Harrison', 'Chase'], ['Lang', 'Chain'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Dolly', 'Too']]\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I now know the final answer\\nFinal Answer: [['Jen', 'Ayai'], ['Harrison', 'Chase'], ['Lang', 'Chain'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Dolly', 'Too']]\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 61,\n",
      "                \"prompt_tokens\": 435,\n",
      "                \"total_tokens\": 496,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-089a68ed-eadc-4510-9f93-244ded2b5bc9-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 61,\n",
      "      \"prompt_tokens\": 435,\n",
      "      \"total_tokens\": 496,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [909ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I now know the final answer\\nFinal Answer: [['Jen', 'Ayai'], ['Harrison', 'Chase'], ['Lang', 'Chain'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Dolly', 'Too']]\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"[['Jen', 'Ayai'], ['Harrison', 'Chase'], ['Lang', 'Chain'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Dolly', 'Too']]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4685",
   "metadata": {},
   "source": [
    "#### Define your own tool  \n",
    "We can define our own tools to perform specific tasks. Here, we will define a tool to get the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b32cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f8b595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c64268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d2fd9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize agent with the new tool\n",
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fcd13cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use the `time` tool to get today's date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-02-11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will try using the `time` tool again to get today's date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "``` \n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-02-11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will try using the `time` tool again to get today's date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "``` \n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-02-11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there was an issue retrieving today's date. Let's try one more time to get the correct date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "``` \n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-02-11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there is an issue with retrieving today's date. Let me try one more time to get the correct date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "``` \n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-02-11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there is an issue with retrieving today's date. Let me try one more time to get the correct date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "``` \n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-02-11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 2025-02-11\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get today's date\n",
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f212652",
   "metadata": {},
   "source": [
    "### LangChain AI Agent Text-to-Speech (TTS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30137863",
   "metadata": {},
   "source": [
    "Below are examples of how to use Text-to-Speech (TTS) tools in LangChain.This tool can be used to convert text into speech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff4bb8",
   "metadata": {},
   "source": [
    "##### Text-to-Speech (TTS) Example    \n",
    "We will use the gTTS (Google Text-to-Speech) library to convert text to speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da13800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# Function to convert text to speech\n",
    "def text_to_speech(text, lang='en'):\n",
    "    # Initialize gTTS object with the text and language\n",
    "    tts = gTTS(text=text, lang=lang, slow=False)\n",
    "    \n",
    "    # Save the speech to an mp3 file\n",
    "    tts.save(\"output.mp3\")\n",
    "    \n",
    "    # Play the speech (optional)\n",
    "    os.system(\"start output.mp3\")  # On Windows, use 'start', on macOS or Linux use 'open'\n",
    "\n",
    "# Example text to convert to speech\n",
    "text = \"Hello, welcome to Langchain! I'm here to help you.\"\n",
    "text_to_speech(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb332d17",
   "metadata": {},
   "source": [
    "#### LangChain SQL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ebfbd",
   "metadata": {},
   "source": [
    "We will create an SQL database and use LangChain to interact with it.  \n",
    "\n",
    "- Example Database Schema (mydatabase.db)  \n",
    "We will create a users table and an orders table with some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a83402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'mydatabase.db' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to (or create) the SQLite database\n",
    "conn = sqlite3.connect(\"mydatabase.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create 'users' table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name TEXT NOT NULL,\n",
    "    email TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Create 'orders' table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS orders (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    user_id INTEGER,\n",
    "    product TEXT NOT NULL,\n",
    "    amount REAL NOT NULL,\n",
    "    FOREIGN KEY (user_id) REFERENCES users(id)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert sample data\n",
    "cursor.executemany(\"INSERT INTO users (name, email) VALUES (?, ?)\", [\n",
    "    (\"Alice\", \"alice@example.com\"),\n",
    "    (\"Bob\", \"bob@example.com\"),\n",
    "    (\"Charlie\", \"charlie@example.com\")\n",
    "])\n",
    "\n",
    "cursor.executemany(\"INSERT INTO orders (user_id, product, amount) VALUES (?, ?, ?)\", [\n",
    "    (1, \"Laptop\", 1200.50),\n",
    "    (2, \"Phone\", 699.99),\n",
    "    (1, \"Headphones\", 150.00),\n",
    "    (3, \"Monitor\", 300.00)\n",
    "])\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Database 'mydatabase.db' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd45f4",
   "metadata": {},
   "source": [
    "Now, when you run your LangChain SQL agent, it will be able to interact with mydatabase.db and query real data. Let's write a complete example where your LangChain SQL agent interacts with the database and queries real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70da8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.caches import BaseCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0762d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.sql_database import SQLDatabase  # Import the correct wrapper\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Setup engine without exposing connection string\n",
    "engine = create_engine(\"sqlite:///mydatabase.db\")  # Example with SQLite\n",
    "\n",
    "# Wrap engine in SQLDatabase\n",
    "db = SQLDatabase(engine)\n",
    "\n",
    "# Create SQL agent\n",
    "db_chain = SQLDatabaseChain.from_llm(OpenAI(temperature=0), db, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a937a1",
   "metadata": {},
   "source": [
    "- Running LangChain SQL Agent  \n",
    "This example will:  \n",
    "✅ Connect to mydatabase.db using LangChain’s SQLDatabase wrapper  \n",
    "✅ Create a LangChain SQL Agent using SQLDatabaseChain  \n",
    "✅ Run a query (e.g., \"Show all users\") using OpenAI’s LLM  \n",
    "\n",
    "**Note** Install Dependencies\n",
    "If you haven’t already, install the required packages:\n",
    "``` py \n",
    "pip install langchain langchain-experimental sqlalchemy sqlite3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac295066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Show all users\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"name\", \"email\" FROM users\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Alice', 'alice@example.com'), ('Bob', 'bob@example.com'), ('Charlie', 'charlie@example.com')]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mAlice, Bob, Charlie\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "📌 Query Result:\n",
      "Alice, Bob, Charlie\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Step 1: Connect to the SQLite Database\n",
    "engine = create_engine(\"sqlite:///mydatabase.db\")  # Connect to SQLite\n",
    "db = SQLDatabase(engine)  # Wrap the engine for LangChain\n",
    "\n",
    "# Step 2: Create the SQL Agent\n",
    "llm = OpenAI(temperature=0)  # Using OpenAI LLM (Make sure API key is set)\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "# Step 3: Run a Query\n",
    "query = \"Show all users\"\n",
    "result = db_chain.run(query)\n",
    "\n",
    "# Step 4: Display Results\n",
    "print(\"\\n📌 Query Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4b389",
   "metadata": {},
   "source": [
    "What’s Happening?  \n",
    "Connects to the SQLite database (mydatabase.db)  \n",
    "Wraps it with LangChain’s SQLDatabase  \n",
    "Creates a LangChain SQLDatabaseChain that uses an OpenAI LLM  \n",
    "Runs a query (\"Show all users\")  \n",
    "Executes SQL (SELECT * FROM users) and returns formatted results  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6dc4da",
   "metadata": {},
   "source": [
    "🛠️ Modify & Try More Queries  \n",
    "You can replace query = \"Show all users\" with different prompts, such as:  \n",
    "✅ \"How many users are in the database?\"  \n",
    "✅ \"List all orders with their amounts.\"  \n",
    "✅ \"Who ordered a Laptop?\"  \n",
    "\n",
    "LangChain will translate these into proper SQL queries!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many users are in the database?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(*) FROM users\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(3,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m3\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "📌 Query Result:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run a new Query\n",
    "query = \"How many users are in the database?\"\n",
    "result = db_chain.run(query)\n",
    "\n",
    "# Step 4: Display Results\n",
    "print(\"\\n📌 Query Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3940cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "List all orders with their amounts.\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"orders\".\"product\", \"orders\".\"amount\" FROM \"orders\" LIMIT 5\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Laptop', 1200.5), ('Phone', 699.99), ('Headphones', 150.0), ('Monitor', 300.0)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m[('Laptop', 1200.5), ('Phone', 699.99), ('Headphones', 150.0), ('Monitor', 300.0)]\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "📌 Query Result:\n",
      "[('Laptop', 1200.5), ('Phone', 699.99), ('Headphones', 150.0), ('Monitor', 300.0)]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run a new Query\n",
    "query = \"List all orders with their amounts.\"\n",
    "result = db_chain.run(query)\n",
    "\n",
    "# Step 4: Display Results\n",
    "print(\"\\n📌 Query Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839390f",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "In this notebook, we have explored `various functionalities of LangChain agents`, including using built-in tools, defining custom tools, working with a Python agent, and interacting with an SQL database. By leveraging these capabilities, we can build powerful and flexible AI agents for a wide range of applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcd3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
