{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions üè∑Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34349d",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "This notebook demonstrates `how to perform tagging and extraction using OpenAI functions in combination with Langchain`. The main focus is on tagging text with specific attributes such as sentiment and language, and extracting structured information from text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcbde",
   "metadata": {},
   "source": [
    "`Sentiment analysis` is a natural language processing (NLP) technique used to determine the sentiment or emotional tone behind a piece of text. This can be categorized as positive, negative, or neutral. Sentiment analysis is widely used in various applications such as social media monitoring, customer feedback analysis, and market research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05495737",
   "metadata": {},
   "source": [
    "### Setup the Environment, OpenAI API Key  and Imports\n",
    "First, we need to import the necessary libraries and set up the Environemnt and the OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Print OpenAI API key (masked)\n",
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')[:5]}*****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8ae3a",
   "metadata": {},
   "source": [
    "**Note** Ensure you have the required packages installed:\n",
    "```py\n",
    "%pip install pydantic==1.10.8\n",
    "%pip install rich\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3611c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from rich library that helps to improve the readability of nested dictionary outputs\n",
    "from rich import print\n",
    "from rich.pretty import Pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from Pydantic \n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Import necessary modules from  Langchain\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe58c35",
   "metadata": {},
   "source": [
    "### Example Using OpenAI and Langchain\n",
    "Here is a simplified example of how you can perform sentiment analysis using OpenAI and Langchain:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1714bc8",
   "metadata": {},
   "source": [
    "- Define a Tagging model using Pydantic to specify the sentiment and language fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ae5481-4155-4831-a5dd-4c183b3b4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model for Tagging\n",
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e72cc",
   "metadata": {},
   "source": [
    "- Use the convert_pydantic_to_openai_function utility to convert this model into an OpenAI function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd656b2-62be-49d4-a277-b920c67203c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_7620\\462419868.py:2: LangChainDeprecationWarning: The function `_convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  convert_pydantic_to_openai_function(Tagging)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'properties': {'sentiment': {'description': 'sentiment of text, should be `pos`, `neg`, or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'language of text (should be ISO 639-1 code)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Pydantic model to OpenAI function\n",
    "convert_pydantic_to_openai_function(Tagging)\n",
    "\n",
    "# Display the converted function in a pretty format\n",
    "print(Pretty(convert_pydantic_to_openai_function(Tagging)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126619ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tagging'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tag the piece of text with particular info.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'sentiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sentiment of text, should be `pos`, `neg`, or `neutral`'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'language of text (should be ISO 639-1 code)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'sentiment'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'Tagging'\u001b[0m,\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m'Tag the piece of text with particular info.'\u001b[0m,\n",
       "    \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'sentiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'description'\u001b[0m: \u001b[32m'sentiment of text, should be `pos`, `neg`, or `neutral`'\u001b[0m,\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'language of text \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshould be ISO 639-1 code\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'sentiment'\u001b[0m, \u001b[32m'language'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(convert_pydantic_to_openai_function(Tagging)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed8b15a7-450c-43d6-af44-ca63800a4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for Langchain prompts and chat models\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61cafb",
   "metadata": {},
   "source": [
    "- Create a ChatOpenAI model and bind it with the tagging functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc5bac3-3783-4ce7-9de6-83c905fba7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_7620\\437840587.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(temperature=0)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798ac5b3-7e47-4cfb-8173-63900cf1e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tagging functions\n",
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65372cc",
   "metadata": {},
   "source": [
    "- Finally, let's create a prompt template and a tagging chain to analyze the sentiment of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d558031-18cf-4791-b061-8911ce314605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for tagging\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00607aff-a64e-42b7-8cf4-893e8393dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the model with functions\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0bc519-2b8e-40d0-88ec-fc5ef0291f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tagging chain\n",
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595b02a",
   "metadata": {},
   "source": [
    "-  Test the tagging chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688fdba-0996-446c-a77b-318094944998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tagging chain\n",
    "tagging_chain.invoke({\"input\": \"I love langchain\"})\n",
    "\n",
    "# Display the tagging chain in a pretty format\n",
    "print(Pretty(tagging_chain.invoke({\"input\": \"I love langchain\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"sentiment\":\"pos\",\"language\":\"en\"}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tagging'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-267e9b10-acf8-457a-b27f-1697bd2556ff-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"sentiment\":\"pos\",\"language\":\"en\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'Tagging'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m108\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m119\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-267e9b10-acf8-457a-b27f-1697bd2556ff-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(tagging_chain.invoke({\"input\": \"I love langchain\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b4946",
   "metadata": {},
   "source": [
    "**Explanation output** The above output is an instance of an AIMessage, which encapsulates the response from an AI model with a given input (I love langchain). In summary, the AI model was called to tag a piece of text, identifying it as `having a positive sentiment and being in English`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tagging chain with a different input\n",
    "tagging_chain.invoke({\"input\": \"Ik houd niet van het Nederlandse weer\"})\n",
    "\n",
    "# Display the tagging chain in a pretty format\n",
    "print(Pretty(tagging_chain.invoke({\"input\": \"Ik houd niet van het Nederlandse weer\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acf4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"sentiment\":\"neg\",\"language\":\"nl\"}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tagging'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">124</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-12f0df6d-90ca-4c51-aabb-7cd51f861392-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"sentiment\":\"neg\",\"language\":\"nl\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'Tagging'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m113\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m124\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-12f0df6d-90ca-4c51-aabb-7cd51f861392-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(tagging_chain.invoke({\"input\": \"Ik houd niet van het Nederlandse weer\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684a69e9",
   "metadata": {},
   "source": [
    "**Explanation output** Using a different input, the above output has identified the input as `having a negative sentiment and being in Dutch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0749e408-3878-4ddd-ad33-8d5b8418a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the JsonOutputFunctionsParser\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc45243e-7225-427d-b679-d737ebaec780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tagging chain with JSON output parser\n",
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbba085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'nl'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tagging chain with JSON output parser\n",
    "tagging_chain.invoke({\"input\": \"Ik houd niet van het Nederlandse weer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e417b4-9306-413f-865f-e13dbd2d0196",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97338dce-a61a-4f8b-912c-6108dcb86183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model for Person\n",
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f558fb45-f3a5-47be-8778-dddec2d00ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model for Information\n",
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb6028-0ade-46f6-a899-ca10f185bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pydantic model to OpenAI function\n",
    "convert_pydantic_to_openai_function(Information)\n",
    "\n",
    "# Print the function on a pretty way \n",
    "print(Pretty(convert_pydantic_to_openai_function(Information)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc963166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Information'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Information to extract.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'people'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'List of info about people'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'items'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Information about a person.'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"person's name\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'age'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'anyOf'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'integer'</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'null'</span><span style=\"font-weight: bold\">}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"person's age\"</span><span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'age'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'array'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'people'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'Information'\u001b[0m,\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m'Information to extract.'\u001b[0m,\n",
       "    \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'people'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'description'\u001b[0m: \u001b[32m'List of info about people'\u001b[0m,\n",
       "                \u001b[32m'items'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'description'\u001b[0m: \u001b[32m'Information about a person.'\u001b[0m,\n",
       "                    \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'name'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m\"person's name\"\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'age'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'anyOf'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'integer'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'null'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m\"person's age\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'name'\u001b[0m, \u001b[32m'age'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'array'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'people'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(convert_pydantic_to_openai_function(Information)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f16ce50e-bad7-4fbb-b9e2-0adae6fc55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the extraction functions\n",
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f783ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the extraction model\n",
    "extraction_model.invoke(\"Pinco is 30, his mom is Jane\")\n",
    "\n",
    "# Print the extraction model in a pretty way \n",
    "print(Pretty(extraction_model.invoke(\"Pinco is 30, his mom is Jane\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"people\":[{\"name\":\"Pinco\",\"age\":30},{\"name\":\"Palla\",\"age\":null}]}'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Information'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-a3497fce-4492-49d2-b2c9-ccbdc0a39048-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"people\":\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\":\"Pinco\",\"age\":30\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\":\"Palla\",\"age\":null\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'Information'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m23\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m97\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m120\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-a3497fce-4492-49d2-b2c9-ccbdc0a39048-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(extraction_model.invoke(\"Pinco is 30, his mom is Jane\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "172df097-250a-4813-b76d-21436c13056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for extraction\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfec48d7-25a2-46d7-a7a2-33284b577dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extraction chain\n",
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19622af-4b01-4145-ae5a-af15b551a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the extraction chain\n",
    "extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})\n",
    "\n",
    "# Print the extracht chain in a pretty way \n",
    "print(Pretty(extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6759bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"people\":[{\"name\":\"Pinco\",\"age\":30},{\"name\":\"Palla\"}]}'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Information'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">133</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-90002214-6cef-4323-af8c-ef7947c06fef-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"people\":\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\":\"Pinco\",\"age\":30\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\":\"Palla\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'Information'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m114\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m133\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-90002214-6cef-4323-af8c-ef7947c06fef-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38989431-9a61-461e-a86f-61a7dddab63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extraction chain with JSON output parser\n",
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13ac89c9-1e8d-4e11-8bca-909a6c34d23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Pinco', 'age': 30}, {'name': 'Palla'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the extraction chain with JSON output parser\n",
    "extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bc255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'people'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Pinco'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'age'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Palla'</span><span style=\"font-weight: bold\">}]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'people'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'Pinco'\u001b[0m, \u001b[32m'age'\u001b[0m: \u001b[1;36m30\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'Palla'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8db4b39-c28b-4c0e-8b9a-55ceb8ba817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901d3ac-4dfc-4fb9-afd3-ab056489d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extraction chain where the input prompt is processed through the \n",
    "# extraction_model, and the resulting output is parsed to extract the value \n",
    "# associated with the key \"people\" using JsonKeyOutputFunctionsParser.\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7eff400-9f3a-42a8-ba4a-a3757e7939e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Pinco', 'age': 30}, {'name': 'Palla', 'age': None}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701fec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Pinco'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'age'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Palla'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'age'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'Pinco'\u001b[0m, \u001b[32m'age'\u001b[0m: \u001b[1;36m30\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'Palla'\u001b[0m, \u001b[32m'age'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(extraction_chain.invoke({\"input\": \"Pinco is 30, his mom is Jane\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8524f3-a663-4007-ad59-52dfe00343e9",
   "metadata": {},
   "source": [
    "## Doing it for real\n",
    "\n",
    "We can apply tagging to a larger body of text.\n",
    "\n",
    "For example, let's load this blog post and extract tag information from a sub-set of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc7c4a8c-d4c8-4400-b1d3-5c7c0c25786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Load a document from the web using WebBaseLoader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9d73e",
   "metadata": {},
   "source": [
    "**Note** The above output shows up a warninig of setting the USER_AGENT environment variable, you ensure that your requests are properly identified, which can improve compatibility and compliance with web servers' policies. However, in this case, the warning about the USER_AGENT environment variable not being set does not affect the functionality of the analysis in the provided file. It is simply a recommendation to provide better identification for your requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbd2e910-e0e0-447a-8118-6fe792f04e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first document from the loaded documents\n",
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5e39f78-ff18-4016-a751-7d0e4c82bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 10,000 characters of the document's content\n",
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb8d98ee-e9b2-4ce8-982a-c06dc006da76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "LLM Powered Autonomous Agents | Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "|\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Posts\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Archive\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Search\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Tags\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "FAQ\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "emojisearch.app\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "      LLM Powered Autonomous Agents\n",
       "    \n",
       "Date: June <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>  |  Estimated Reading Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "\n",
       "Table of Contents\n",
       "\n",
       "\n",
       "\n",
       "Agent System Overview\n",
       "\n",
       "Component One: Planning\n",
       "\n",
       "Task Decomposition\n",
       "\n",
       "Self-Reflection\n",
       "\n",
       "\n",
       "Component Two: Memory\n",
       "\n",
       "Types of Memory\n",
       "\n",
       "Maximum Inner Product Search <span style=\"font-weight: bold\">(</span>MIPS<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "\n",
       "Component Three: Tool Use\n",
       "\n",
       "Case Studies\n",
       "\n",
       "Scientific Discovery Agent\n",
       "\n",
       "Generative Agents Simulation\n",
       "\n",
       "Proof-of-Concept Examples\n",
       "\n",
       "\n",
       "Challenges\n",
       "\n",
       "Citation\n",
       "\n",
       "References\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Building agents with LLM <span style=\"font-weight: bold\">(</span>large language model<span style=\"font-weight: bold\">)</span> as its core controller is a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful gene\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "LLM Powered Autonomous Agents | Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "|\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Posts\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Archive\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Search\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Tags\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "FAQ\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "emojisearch.app\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "      LLM Powered Autonomous Agents\n",
       "    \n",
       "Date: June \u001b[1;36m23\u001b[0m, \u001b[1;36m2023\u001b[0m  |  Estimated Reading Time: \u001b[1;36m31\u001b[0m min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "\n",
       "Table of Contents\n",
       "\n",
       "\n",
       "\n",
       "Agent System Overview\n",
       "\n",
       "Component One: Planning\n",
       "\n",
       "Task Decomposition\n",
       "\n",
       "Self-Reflection\n",
       "\n",
       "\n",
       "Component Two: Memory\n",
       "\n",
       "Types of Memory\n",
       "\n",
       "Maximum Inner Product Search \u001b[1m(\u001b[0mMIPS\u001b[1m)\u001b[0m\n",
       "\n",
       "\n",
       "Component Three: Tool Use\n",
       "\n",
       "Case Studies\n",
       "\n",
       "Scientific Discovery Agent\n",
       "\n",
       "Generative Agents Simulation\n",
       "\n",
       "Proof-of-Concept Examples\n",
       "\n",
       "\n",
       "Challenges\n",
       "\n",
       "Citation\n",
       "\n",
       "References\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Building agents with LLM \u001b[1m(\u001b[0mlarge language model\u001b[1m)\u001b[0m as its core controller is a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful gene\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the first 1,000 characters of the page content for a quick preview\n",
    "print(page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9db0d107-5284-4253-b769-dfedb97ce95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model for Overview\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bfe7fe6-a86d-416c-a7f2-373dc70fcba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pydantic model to an OpenAI function\n",
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "\n",
    "# Bind the model with the tagging functions and specify the function call\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "\n",
    "# Create a tagging chain using the prompt, model, and JSON output parser\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f2337-a8eb-4eff-b764-b70e48545d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tagging chain with the page content\n",
    "tagging_chain.invoke({\"input\": page_content})\n",
    "\n",
    "# Print the function in a pretty way \n",
    "print(Pretty(tagging_chain.invoke({\"input\": page_content})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The text discusses the concept of building autonomous agents powered by LLM (large language model) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as the core controller. It covers components like planning, memory, and tool use, along with techniques such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task decomposition and self-reflection.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'English'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'keywords'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LLM, autonomous agents, planning, memory, tool use, task decomposition, self-reflection'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'summary'\u001b[0m: \u001b[32m'The text discusses the concept of building autonomous agents powered by LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mas the core controller. It covers components like planning, memory, and tool use, along with techniques such as \u001b[0m\n",
       "\u001b[32mtask decomposition and self-reflection.'\u001b[0m,\n",
       "    \u001b[32m'language'\u001b[0m: \u001b[32m'English'\u001b[0m,\n",
       "    \u001b[32m'keywords'\u001b[0m: \u001b[32m'LLM, autonomous agents, planning, memory, tool use, task decomposition, self-reflection'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(tagging_chain.invoke({\"input\": page_content})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5be5d604-3d95-476a-afe4-b46b021534fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e56ca98-d05d-4199-a6ec-fe485b630da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}\n",
    ")\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f082b7a0-b7ea-488a-923c-aba8e4b185a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LLM Powered Autonomous Agents', 'author': 'Lilian Weng'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a8dcce7-7032-49a8-893d-1659e2f51f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article follow by its author. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4c8cc-d9a4-4556-a89e-94ec981c6f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extraction chain where the input prompt is processed through the extraction_model,\n",
    "# and the resulting output is parsed to extract the value associated with the key \"papers\"\n",
    "# using JsonKeyOutputFunctionsParser.\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e00b6-0f06-4e74-948e-04805e66f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extraction chain with the given input (page_content) to process and extract the desired information.\n",
    "extraction_chain.invoke({\"input\": page_content})\n",
    "\n",
    "# Print the desired information in a pretty way \n",
    "print(Pretty(extraction_chain.invoke({\"input\": page_content})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13ea54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chain of thought (CoT; Wei et al. 2022)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Wei et al. 2022'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts (Yao et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Yao et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LLM+P (Liu et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liu et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ReAct (Yao et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Yao et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Reflexion (Shinn &amp; Labash 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Shinn &amp; Labash 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chain of Hindsight (CoH; Liu et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liu et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Algorithm Distillation (AD; Laskin et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Laskin et al. 2023'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Chain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Wei et al. 2022'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Tree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Yao et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'LLM+P \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Liu et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ReAct \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Yao et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Reflexion \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShinn & Labash 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Shinn & Labash 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Chain of Hindsight \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoH; Liu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Liu et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Algorithm Distillation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAD; Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Laskin et al. 2023'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(extraction_chain.invoke({\"input\": page_content})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "365bfa5b-f0d2-4a19-8db1-1b4a0f51703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Paper A', 'author': 'Author A'},\n",
       " {'title': 'Paper B', 'author': 'Author B'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a3e18b5-0692-49dc-b589-5d4ae5a43fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851b07c-0f73-4cf1-801f-9832190db93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the document's page content into smaller chunks using the text_splitter.\n",
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364aee1",
   "metadata": {},
   "source": [
    "**Note** \"chunks\" refer to smaller segments or pieces of a larger text. These chunks can be sentences, paragraphs, or other sub-divisions of the text, depending on the specific application and the method used for splitting the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6fd3c-8fca-4f16-a256-a66577b48eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of chunks created by the text_splitter from the document's page content.\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1309bf-16a5-43ef-aa8e-427cf5120938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to flatten a 2D matrix into a 1D list by concatenating all rows.\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5af35566-8f5f-4e02-86d2-c1a97ca4e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77be284-fca5-4ab0-ab36-b83b3ab53136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">LLM Powered Autonomous Agents | Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "|\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Posts\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Archive\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Search\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Tags\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "FAQ\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "emojisearch.app\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "      LLM Powered Autonomous Agents\n",
       "    \n",
       "Date: June <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>  |  Estimated Reading Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "\n",
       "Table of Contents\n",
       "\n",
       "\n",
       "\n",
       "Agent System Overview\n",
       "\n",
       "Component One: Planning\n",
       "\n",
       "Task Decomposition\n",
       "\n",
       "Self-Reflection\n",
       "\n",
       "\n",
       "Component Two: Memory\n",
       "\n",
       "Types of Memory\n",
       "\n",
       "Maximum Inner Product Search <span style=\"font-weight: bold\">(</span>MIPS<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "\n",
       "Component Three: Tool Use\n",
       "\n",
       "Case Studies\n",
       "\n",
       "Scientific Discovery Agent\n",
       "\n",
       "Generative Agents Simulation\n",
       "\n",
       "Proof-of-Concept Examples\n",
       "\n",
       "\n",
       "Challenges\n",
       "\n",
       "Citation\n",
       "\n",
       "References\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Building agents with LLM <span style=\"font-weight: bold\">(</span>large language model<span style=\"font-weight: bold\">)</span> as its core controller is a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem\n",
       "solver.\n",
       "Agent System Overview#\n",
       "In a LLM-powered autonomous agent system, LLM functions as the agent‚Äôs brain, complemented by several key \n",
       "components:\n",
       "\n",
       "Planning\n",
       "\n",
       "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient \n",
       "handling of complex tasks.\n",
       "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from \n",
       "mistakes and refine them for future steps, thereby improving the quality of final results.\n",
       "\n",
       "\n",
       "Memory\n",
       "\n",
       "Short-term memory: I would consider all the in-context learning <span style=\"font-weight: bold\">(</span>See Prompt Engineering<span style=\"font-weight: bold\">)</span> as utilizing short-term \n",
       "memory of the model to learn.\n",
       "Long-term memory: This provides the agent with the capability to retain and recall <span style=\"font-weight: bold\">(</span>infinite<span style=\"font-weight: bold\">)</span> information over \n",
       "extended periods, often by leveraging an external vector store and fast retrieval.\n",
       "\n",
       "\n",
       "Tool use\n",
       "\n",
       "The agent learns to call external APIs for extra information that is missing from the model weights <span style=\"font-weight: bold\">(</span>often hard to \n",
       "change after pre-training<span style=\"font-weight: bold\">)</span>, including current information, code execution capability, access to proprietary \n",
       "information sources and more.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "LLM Powered Autonomous Agents | Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Lil'Log\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "|\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Posts\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Archive\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Search\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Tags\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "FAQ\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "emojisearch.app\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "      LLM Powered Autonomous Agents\n",
       "    \n",
       "Date: June \u001b[1;36m23\u001b[0m, \u001b[1;36m2023\u001b[0m  |  Estimated Reading Time: \u001b[1;36m31\u001b[0m min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "\n",
       "Table of Contents\n",
       "\n",
       "\n",
       "\n",
       "Agent System Overview\n",
       "\n",
       "Component One: Planning\n",
       "\n",
       "Task Decomposition\n",
       "\n",
       "Self-Reflection\n",
       "\n",
       "\n",
       "Component Two: Memory\n",
       "\n",
       "Types of Memory\n",
       "\n",
       "Maximum Inner Product Search \u001b[1m(\u001b[0mMIPS\u001b[1m)\u001b[0m\n",
       "\n",
       "\n",
       "Component Three: Tool Use\n",
       "\n",
       "Case Studies\n",
       "\n",
       "Scientific Discovery Agent\n",
       "\n",
       "Generative Agents Simulation\n",
       "\n",
       "Proof-of-Concept Examples\n",
       "\n",
       "\n",
       "Challenges\n",
       "\n",
       "Citation\n",
       "\n",
       "References\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Building agents with LLM \u001b[1m(\u001b[0mlarge language model\u001b[1m)\u001b[0m as its core controller is a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends \n",
       "beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem\n",
       "solver.\n",
       "Agent System Overview#\n",
       "In a LLM-powered autonomous agent system, LLM functions as the agent‚Äôs brain, complemented by several key \n",
       "components:\n",
       "\n",
       "Planning\n",
       "\n",
       "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient \n",
       "handling of complex tasks.\n",
       "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from \n",
       "mistakes and refine them for future steps, thereby improving the quality of final results.\n",
       "\n",
       "\n",
       "Memory\n",
       "\n",
       "Short-term memory: I would consider all the in-context learning \u001b[1m(\u001b[0mSee Prompt Engineering\u001b[1m)\u001b[0m as utilizing short-term \n",
       "memory of the model to learn.\n",
       "Long-term memory: This provides the agent with the capability to retain and recall \u001b[1m(\u001b[0minfinite\u001b[1m)\u001b[0m information over \n",
       "extended periods, often by leveraging an external vector store and fast retrieval.\n",
       "\n",
       "\n",
       "Tool use\n",
       "\n",
       "The agent learns to call external APIs for extra information that is missing from the model weights \u001b[1m(\u001b[0moften hard to \n",
       "change after pre-training\u001b[1m)\u001b[0m, including current information, code execution capability, access to proprietary \n",
       "information sources and more.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the first chunk from the list of text chunks created by the text_splitter.\n",
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67bded5d-de85-488c-bd3f-d83acbcfea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04233d0a-fe44-45ed-9145-af3caaa86863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a RunnableLambda that prepares the input by splitting the text into chunks using text_splitter,\n",
    "# and then formats each chunk as a dictionary with the key \"input\".\n",
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa8c2f1e-f3ac-4d9c-8ded-541778a32ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'hi'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d0255-4b58-42c9-a747-44768a866633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a processing chain where the input is first prepared by splitting the text into chunks,\n",
    "# then each chunk is processed through the extraction_chain in parallel using the map function,\n",
    "# and finally, the results are flattened into a single list.\n",
    "chain = prep | extraction_chain.map() | flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa1f67-7246-4f4f-8967-4d7266df7b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'AutoGPT', 'author': None},\n",
       " {'title': 'GPT-Engineer', 'author': None},\n",
       " {'title': 'BabyAGI', 'author': None},\n",
       " {'title': 'Chain of thought', 'author': 'Wei et al. 2022'},\n",
       " {'title': 'Tree of Thoughts', 'author': 'Yao et al. 2023'},\n",
       " {'title': 'LLM+P', 'author': 'Liu et al. 2023'},\n",
       " {'title': 'ReAct', 'author': 'Yao et al. 2023'},\n",
       " {'title': 'Reflexion', 'author': 'Shinn & Labash 2023'},\n",
       " {'title': 'Chain of Hindsight (CoH)', 'author': 'Liu et al. 2023'},\n",
       " {'title': 'Algorithm Distillation (AD)', 'author': 'Laskin et al. 2023'},\n",
       " {'title': 'Miller 1956', 'author': None},\n",
       " {'title': 'Duan et al. 2017', 'author': None},\n",
       " {'title': 'LSH: Locality-Sensitive Hashing', 'author': None},\n",
       " {'title': 'ANNOY: Approximate Nearest Neighbors Oh Yeah', 'author': None},\n",
       " {'title': 'HNSW: Hierarchical Navigable Small World', 'author': None},\n",
       " {'title': 'FAISS: Facebook AI Similarity Search', 'author': None},\n",
       " {'title': 'ScaNN: Scalable Nearest Neighbors', 'author': None},\n",
       " {'title': 'MRKL (Karpas et al. 2022)', 'author': None},\n",
       " {'title': 'TALM (Tool Augmented Language Models; Parisi et al. 2022)',\n",
       "  'author': None},\n",
       " {'title': 'Toolformer (Schick et al. 2023)', 'author': None},\n",
       " {'title': 'HuggingGPT (Shen et al. 2023)', 'author': None},\n",
       " {'title': 'API-Bank', 'author': 'Li et al. 2023'},\n",
       " {'title': 'ChemCrow', 'author': 'Bran et al. 2023'},\n",
       " {'title': 'Boiko et al. (2023)', 'author': 'null'},\n",
       " {'title': 'Generative Agents Simulation', 'author': 'Park, et al. (2023)'},\n",
       " {'title': 'Park et al. 2023', 'author': None},\n",
       " {'title': 'Super Mario: How Nintendo Conquered America',\n",
       "  'author': 'Jeff Ryan'},\n",
       " {'title': 'The Design of Super Mario Bros.', 'author': 'Shigeru Miyamoto'},\n",
       " {'title': 'Paper A', 'author': 'Author X'},\n",
       " {'title': 'Paper B', 'author': 'Author Y'},\n",
       " {'title': 'Chain of thought prompting elicits reasoning in large language models',\n",
       "  'author': 'Wei et al.'},\n",
       " {'title': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Chain of Hindsight Aligns Language Models with Feedback',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'ReAct: Synergizing reasoning and acting in language models',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Reflexion: an autonomous agent with dynamic memory and self-reflection',\n",
       "  'author': 'Shinn & Labash'},\n",
       " {'title': 'In-context Reinforcement Learning with Algorithm Distillation',\n",
       "  'author': 'Laskin et al.'},\n",
       " {'title': 'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning',\n",
       "  'author': 'Karpas et al.'},\n",
       " {'title': 'Webgpt: Browser-assisted question-answering with human feedback',\n",
       "  'author': 'Nakano et al.'},\n",
       " {'title': 'Toolformer: Language Models Can Teach Themselves to Use Tools',\n",
       "  'author': 'Schick et al.'},\n",
       " {'title': 'API-Bank: A Benchmark for Tool-Augmented LLMs',\n",
       "  'author': 'Li et al.'},\n",
       " {'title': 'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace',\n",
       "  'author': 'Shen et al.'},\n",
       " {'title': 'ChemCrow: Augmenting large-language models with chemistry tools',\n",
       "  'author': 'Bran et al.'},\n",
       " {'title': 'Emergent autonomous scientific research capabilities of large language models',\n",
       "  'author': 'Boiko et al.'},\n",
       " {'title': 'Generative Agents: Interactive Simulacra of Human Behavior',\n",
       "  'author': 'Joon Sung Park, et al.'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the model \n",
    "chain.invoke(doc.page_content)\n",
    "\n",
    "# Print in a pretty format \n",
    "print(Pretty(chain.invoke(doc.page_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0eac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'AutoGPT'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'GPT-Engineer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'BabyAGI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chain of thought'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Wei et al. 2022'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Yao et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LLM+P'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liu et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ReAct'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Yao et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Reflexion'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Shinn &amp; Labash 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chain of Hindsight (CoH)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liu et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Algorithm Distillation (AD)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Laskin et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Miller 1956'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Duan et al. 2017'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LSH (Locality-Sensitive Hashing)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ANNOY (Approximate Nearest Neighbors Oh Yeah)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HNSW (Hierarchical Navigable Small World)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'FAISS (Facebook AI Similarity Search)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ScaNN (Scalable Nearest Neighbors)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MRKL (Karpas et al. 2022)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'TALM (Tool Augmented Language Models; Parisi et al. 2022)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Toolformer (Schick et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HuggingGPT (Shen et al. 2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'API-Bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Li et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChemCrow'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Bran et al. 2023'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Boiko et al. (2023)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'null'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Generative Agents Simulation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Park, et al. (2023)'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Park et al. 2023'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Unknown'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Super Mario: Designing the Perfect Level'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'John Smith'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MVC Components in Python'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emily Johnson'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'A Study on Machine Learning Algorithms'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'John Smith'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Deep Learning Techniques for Image Recognition'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emily Brown'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pytest'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dataclasses'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chain of thought prompting elicits reasoning in large language models'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Wei et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Yao et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chain of Hindsight Aligns Language Models with Feedback'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liu et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liu et al.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ReAct: Synergizing reasoning and acting in language models'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Yao et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Reflexion: an autonomous agent with dynamic memory and self-reflection'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Shinn &amp; Labash'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'In-context Reinforcement Learning with Algorithm Distillation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Laskin et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge sources and discrete reasoning'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Karpas et al.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Webgpt: Browser-assisted question-answering with human feedback'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Nakano et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'TALM: Tool Augmented Language Models'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Parisi et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Toolformer: Language Models Can Teach Themselves to Use Tools'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Schick et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'API-Bank: A Benchmark for Tool-Augmented LLMs'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Li et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Shen et al.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ChemCrow: Augmenting large-language models with chemistry tools'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Bran et al.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emergent autonomous scientific research capabilities of large language models'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Boiko et al.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Generative Agents: Interactive Simulacra of Human Behavior'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Joon Sung Park, et al.'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'AutoGPT'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'GPT-Engineer'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'BabyAGI'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Chain of thought'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Wei et al. 2022'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Tree of Thoughts'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Yao et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'LLM+P'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Liu et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ReAct'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Yao et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Reflexion'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Shinn & Labash 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Chain of Hindsight \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoH\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Liu et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Algorithm Distillation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Laskin et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Miller 1956'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Duan et al. 2017'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'LSH \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLocality-Sensitive Hashing\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ANNOY \u001b[0m\u001b[32m(\u001b[0m\u001b[32mApproximate Nearest Neighbors Oh Yeah\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'HNSW \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHierarchical Navigable Small World\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'FAISS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFacebook AI Similarity Search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ScaNN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mScalable Nearest Neighbors\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'MRKL \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKarpas et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'TALM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTool Augmented Language Models; Parisi et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Toolformer \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchick et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'HuggingGPT \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'API-Bank'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Li et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ChemCrow'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Bran et al. 2023'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Boiko et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'null'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Generative Agents Simulation'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Park, et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Park et al. 2023'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Unknown'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Super Mario: Designing the Perfect Level'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'John Smith'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'MVC Components in Python'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Emily Johnson'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'A Study on Machine Learning Algorithms'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'John Smith'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Deep Learning Techniques for Image Recognition'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Emily Brown'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'pytest'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'dataclasses'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Chain of thought prompting elicits reasoning in large language models'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Wei et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Yao et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Chain of Hindsight Aligns Language Models with Feedback'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Liu et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Liu et al.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ReAct: Synergizing reasoning and acting in language models'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Yao et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'Reflexion: an autonomous agent with dynamic memory and self-reflection'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Shinn & Labash'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'In-context Reinforcement Learning with Algorithm Distillation'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Laskin et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external\u001b[0m\n",
       "\u001b[32mknowledge sources and discrete reasoning'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Karpas et al.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Webgpt: Browser-assisted question-answering with human feedback'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Nakano et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'TALM: Tool Augmented Language Models'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Parisi et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Toolformer: Language Models Can Teach Themselves to Use Tools'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Schick et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'API-Bank: A Benchmark for Tool-Augmented LLMs'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Li et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Shen et al.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'ChemCrow: Augmenting large-language models with chemistry tools'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Bran et al.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'Emergent autonomous scientific research capabilities of large language models'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Boiko et al.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Generative Agents: Interactive Simulacra of Human Behavior'\u001b[0m, \u001b[32m'author'\u001b[0m: \u001b[32m'Joon Sung Park, et al.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(Pretty(chain.invoke(doc.page_content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb460a-2b56-42be-acf6-4f61e40027f4",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "This notebook demonstrated how to `use OpenAI functions in combination with Langchain to perform tagging and extraction on text`. By defining Pydantic models and converting them to OpenAI functions, we were able to tag text with specific attributes and extract structured information. This approach can be extended to more complex use cases and integrated into larger applications. Besides, sentiment analysis is a powerful tool for understanding the emotional tone of text. By using OpenAI and Langchain, you can easily `implement sentiment analysis in your applications to gain insights from textual data`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
