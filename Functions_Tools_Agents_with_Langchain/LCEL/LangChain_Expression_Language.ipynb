{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc925562",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL) ðŸ”— "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a7b96a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates the `use of the LangChain Expression Language (LCEL) to create and run various chains using LangChain's capabilities`. We will cover the setup, simple chains, more complex chains, and using OpenAI functions. Additionally, we will discuss handling fallbacks and improving output readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07054761",
   "metadata": {},
   "source": [
    "### Setup the Environment, OpenAI API Key  and Imports\n",
    "First, we need to import the necessary libraries and set up the environment and the OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-ft*****\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Print OpenAI API key (masked)\n",
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')[:5]}*****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838ac33",
   "metadata": {},
   "source": [
    "**Note** Ensure you have the required packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de9d2bd-18de-44d5-81ac-5918e2106367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules from langchain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13db6691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rich in c:\\users\\michela\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (13.9.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\michela\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\michela\\appdata\\roaming\\python\\python312\\site-packages (from rich) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\michela\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "#Using the rich library to improve the readability of nested dictionary outputs.\n",
    "%pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29339e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules from langchain\n",
    "from rich import print\n",
    "from rich.pretty import Pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e7c25",
   "metadata": {},
   "source": [
    "We will start with a simple chain that generates a joke based on a given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0be20d-0e00-478c-a844-017cad13af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_15520\\551848145.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI()\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "\n",
    "# Initialize the model and output parser\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chain\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do bears have hairy coats?\\n\\nFur protection!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the chain with a topic\n",
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00c665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the British man bring a ladder to the bar? Because he heard the drinks were on the house!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the chain with a topic\n",
    "chain.invoke({\"topic\": \"British people\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
   "metadata": {},
   "source": [
    "## More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt.We will now create a more complex chain using a retriever to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from Langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_15520\\2361442535.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding=OpenAIEmbeddings()\n",
      "c:\\Users\\Michela\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store from texts\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df87934-1697-405c-b460-5e9bfd16c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_15520\\3641190296.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents(\"where did harrison work?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
       " Document(metadata={}, page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve relevant documents based on a query1\n",
    "retriever.get_relevant_documents(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve relevant documents based on a query2\n",
    "retriever.get_relevant_documents(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebafdee",
   "metadata": {},
   "source": [
    "- Creating the prompt template for a more complex chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the runnable map and chain\n",
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the complex chain\n",
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ec3727-4284-417e-9e23-eec0682eb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(metadata={}, page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca34811",
   "metadata": {},
   "source": [
    "### Bind and Using OpenAI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ac84d",
   "metadata": {},
   "source": [
    "We will demonstrate `how to bind and use OpenAI functions within LangChain`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
   "metadata": {},
   "source": [
    "- Define the OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and runnable\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "620a2007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"EHAM\"}', 'name': 'weather_search'}}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 64, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-ca7e7662-a08b-49c5-9fc4-d6f6be035570-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the model with a query\n",
    "runnable.invoke({\"input\": \"what is the weather in Amsterdam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00ab2573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"airport_code\":\"EHAM\"}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'weather_search'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-f1e9af8e-7bdb-4790-9fe8-9cb95f379a9d-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"airport_code\":\"EHAM\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'weather_search'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m64\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m81\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'function_call'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-f1e9af8e-7bdb-4790-9fe8-9cb95f379a9d-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = runnable.invoke({\"input\": \"what is the weather in Amsterdam\"})\n",
    "\n",
    "# Check if response is a dictionary (JSON-like)\n",
    "if isinstance(response, dict):\n",
    "    print(json.dumps(response, indent=4))  # Pretty-print JSON\n",
    "else:\n",
    "    print(response)  # Print directly if it's a string or another type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65ee4c",
   "metadata": {},
   "source": [
    "**Explanation output** It looks like the output from runnable.invoke() is a structured format and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a22faf5-ea24-48d2-b028-03733b548225",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "        {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b2214",
   "metadata": {},
   "source": [
    "- Bind the function to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the functions to the model\n",
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"New England Patriots\"}', 'name': 'sports_search'}}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 99, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-bf3404e7-4794-4aea-9dc3-920d2c90f6c7-0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a928fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"team_name\":\"New England Patriots\"}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sports_search'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-91f4cc1a-0389-4b43-8a83-7f2e5f3044f6-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"team_name\":\"New England Patriots\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'sports_search'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m102\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m121\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'function_call'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-91f4cc1a-0389-4b43-8a83-7f2e5f3044f6-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "response = runnable.invoke({\"input\": \"what is the latest update on the New England Patriots?\"})\n",
    "\n",
    "# Check if response is a dictionary (JSON-like)\n",
    "if isinstance(response, dict):\n",
    "    print(json.dumps(response, indent=4))  # Pretty-print JSON\n",
    "else:\n",
    "    print(response)  # Print directly if it's a string or another type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af319669",
   "metadata": {},
   "source": [
    "**Explanation output** It looks like the output from runnable.invoke() is a structured response, but it's printed in a raw, unformatted way. You can extract and print it nicely in a structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
   "metadata": {},
   "source": [
    "### Handling Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_15520\\4056484050.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  simple_model = OpenAI(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the fallback model\n",
    "simple_model = OpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=1000, \n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    ")\n",
    "simple_chain = simple_model | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a challenge\n",
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0739e85f-8497-4471-8ec9-17e958d80771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n{\\n    \"title\": \"Autumn Leaves\",\\n    \"author\": \"Emily Dickinson\",\\n    \"first_line\": \"The leaves are falling, one by one\"\\n}\\n\\n{\\n    \"title\": \"The Ocean\\'s Song\",\\n    \"author\": \"Pablo Neruda\",\\n    \"first_line\": \"I hear the ocean\\'s song, a symphony of waves\"\\n}\\n\\n{\\n    \"title\": \"A Winter\\'s Night\",\\n    \"author\": \"Robert Frost\",\\n    \"first_line\": \"The snow falls softly, covering the ground\"\\n}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the fallback chain\n",
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76c22671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'poem1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The Night Sky'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emily Dickinson'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'firstLine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The night is starry and the stars are blue.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'poem2'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Autumn Leaves'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Robert Frost'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'firstLine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"My sorrow, when she's here with me, thinks these dark days of autumn rain are beautiful as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">days can be.\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'poem3'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hope is the Thing with Feathers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emily Dickinson'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'firstLine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hope is the thing with feathers that perches in the soul.'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'poem1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'The Night Sky'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Emily Dickinson'\u001b[0m,\n",
       "        \u001b[32m'firstLine'\u001b[0m: \u001b[32m'The night is starry and the stars are blue.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'poem2'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'Autumn Leaves'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Robert Frost'\u001b[0m,\n",
       "        \u001b[32m'firstLine'\u001b[0m: \u001b[32m\"My sorrow, when she's here with me, thinks these dark days of autumn rain are beautiful as \u001b[0m\n",
       "\u001b[32mdays can be.\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'poem3'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'Hope is the Thing with Feathers'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Emily Dickinson'\u001b[0m,\n",
       "        \u001b[32m'firstLine'\u001b[0m: \u001b[32m'Hope is the thing with feathers that perches in the soul.'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Pretty(chain.invoke(challenge)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Night Sky',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'The night is starry and the stars are blue.'},\n",
       " 'poem2': {'title': 'Autumn Leaves',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': \"My sorrow, when she's here with me, thinks these dark days of autumn rain are beautiful as days can be.\"},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul.'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51f1e5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'poem1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The Rose'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emily Dickinson'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'firstLine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'A rose by any other name would smell as sweet'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'poem2'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The Road Not Taken'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Robert Frost'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'firstLine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Two roads diverged in a yellow wood'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'poem3'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hope is the Thing with Feathers'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Emily Dickinson'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'firstLine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hope is the thing with feathers that perches in the soul'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'poem1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'The Rose'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Emily Dickinson'\u001b[0m,\n",
       "        \u001b[32m'firstLine'\u001b[0m: \u001b[32m'A rose by any other name would smell as sweet'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'poem2'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'The Road Not Taken'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Robert Frost'\u001b[0m,\n",
       "        \u001b[32m'firstLine'\u001b[0m: \u001b[32m'Two roads diverged in a yellow wood'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'poem3'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'title'\u001b[0m: \u001b[32m'Hope is the Thing with Feathers'\u001b[0m,\n",
       "        \u001b[32m'author'\u001b[0m: \u001b[32m'Emily Dickinson'\u001b[0m,\n",
       "        \u001b[32m'firstLine'\u001b[0m: \u001b[32m'Hope is the thing with feathers that perches in the soul'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Pretty(final_chain.invoke(challenge)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4dff75",
   "metadata": {},
   "source": [
    "In this context, the term \"interface\" ilikely refers to the way users interact with the LangChain library to build and run various chains. This involves defining prompts, models, and chains, and then invoking these chains with specific inputs to get desired outputs.  \n",
    "Here the interface is the `set of functions and classes provided by LangChain`, such as `ChatPromptTemplate, ChatOpenAI, StrOutputParser, and RunnableMap`. These components allow users to define and execute chains in a structured and modular way.These components work together to provide a flexible and powerful interface for building and executing chains, enabling users to define complex workflows in a modular and readable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the bear bring a flashlight to the party? \\n\\nBecause he heard the drinks were on the house!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why don't bears wear shoes? \\nBecause they have bear feet!\",\n",
       " 'Why are frogs so happy?\\nBecause they eat whatever bugs them!']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e2f2851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why do British people always carry umbrellas?\\n\\nBecause they can't handle a little bit of drizzle without panicking!\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"British people\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67769929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why do British people never play hide and seek?\\n\\nBecause good luck hiding when you have such terrible teeth!',\n",
       " 'Why did the American man bring a ladder to the bar? \\n\\nBecause he heard the drinks were on the house!']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"British people\"}, {\"topic\": \"American people\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f66bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> do\n",
       "</pre>\n"
      ],
      "text/plain": [
       " do\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> British\n",
       "</pre>\n"
      ],
      "text/plain": [
       " British\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> people\n",
       "</pre>\n"
      ],
      "text/plain": [
       " people\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> always\n",
       "</pre>\n"
      ],
      "text/plain": [
       " always\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> carry\n",
       "</pre>\n"
      ],
      "text/plain": [
       " carry\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> a\n",
       "</pre>\n"
      ],
      "text/plain": [
       " a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> tea\n",
       "</pre>\n"
      ],
      "text/plain": [
       " tea\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> bag\n",
       "</pre>\n"
      ],
      "text/plain": [
       " bag\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> with\n",
       "</pre>\n"
      ],
      "text/plain": [
       " with\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> them\n",
       "</pre>\n"
      ],
      "text/plain": [
       " them\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">?\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "?\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> case\n",
       "</pre>\n"
      ],
      "text/plain": [
       " case\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> they\n",
       "</pre>\n"
      ],
      "text/plain": [
       " they\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> find\n",
       "</pre>\n"
      ],
      "text/plain": [
       " find\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> themselves\n",
       "</pre>\n"
      ],
      "text/plain": [
       " themselves\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> in\n",
       "</pre>\n"
      ],
      "text/plain": [
       " in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> hot\n",
       "</pre>\n"
      ],
      "text/plain": [
       " hot\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> water\n",
       "</pre>\n"
      ],
      "text/plain": [
       " water\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"British people\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> don\n",
       "</pre>\n"
      ],
      "text/plain": [
       " don\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">'t\n",
       "</pre>\n"
      ],
      "text/plain": [
       "'t\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> bears\n",
       "</pre>\n"
      ],
      "text/plain": [
       " bears\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> like\n",
       "</pre>\n"
      ],
      "text/plain": [
       " like\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> fast\n",
       "</pre>\n"
      ],
      "text/plain": [
       " fast\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> food\n",
       "</pre>\n"
      ],
      "text/plain": [
       " food\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Because\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Because\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> they\n",
       "</pre>\n"
      ],
      "text/plain": [
       " they\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> can\n",
       "</pre>\n"
      ],
      "text/plain": [
       " can\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">'t\n",
       "</pre>\n"
      ],
      "text/plain": [
       "'t\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> catch\n",
       "</pre>\n"
      ],
      "text/plain": [
       " catch\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> it\n",
       "</pre>\n"
      ],
      "text/plain": [
       " it\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2ed31",
   "metadata": {},
   "source": [
    "**Explanation output** a joke formatted in a humorous way with additional spaces between each word. The joke goes:  \n",
    "Q: Why did the bear bring a ladder to the bar?  \n",
    "A: Because he heard the drinks were on the house!  \n",
    "\n",
    "The punchline \"the drinks were on the house\" is a play on words, meaning both that the drinks are free (a common idiom) and that the drinks are literally located on the roof, hence the need for a ladder.\n",
    "\n",
    "`The format with extra spaces between each word` can have several advantages such as `emphasis and clarity`, ``visual impact`, `engagement` and `humor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship anymore!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77a5582b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the British man bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"British people\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005703f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrated the use of LangChain Expression Language (LCEL) to create and run various chains. We covered setup, simple and complex chains, using OpenAI functions, improving readability with the rich library, and handling fallbacks. These examples illustrate the flexibility and power of LangChain for building and running chains of different complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d2547",
   "metadata": {},
   "source": [
    "Here's a short description of the interface as used in the notebook:  \n",
    "\n",
    "Interface in LangChain Notebook\n",
    "The LangChain notebook demonstrates how to use the LangChain interface to create and execute chains of operations. This interface includes:  \n",
    "- Prompt Templates: ChatPromptTemplate allows users to define prompts with placeholders for dynamic content.\n",
    "- Models: ChatOpenAI represents the language model used to process prompts and generate responses.\n",
    "- Output Parsers: StrOutputParser parses the model's output into a desired format.\n",
    "= Runnable Maps: RunnableMap allows for the creation of more complex chains by mapping inputs to specific functions or operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
