{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3df44d6-62d0-4324-8052-419503a6b040",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling âœ… \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23297775",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to use `OpenAI's API for function calling with the GPT-3.5-Turbo model`. We'll cover updating the code to use the new API and provide an example function for fetching current weather information.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- OpenAI has announced the release of an updated GPT-3.5-Turbo model and the deprecation of the `gpt-3.5-turbo-0613` model.\n",
    "- The `openai.ChatCompletion.create` has been removed in OpenAI's Python client version 1.0.0 and later. The API has changed, requiring code updates to use the new format such as `client.chat.completions.create`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cabdf1",
   "metadata": {},
   "source": [
    "### Setup the Environment, OpenAI API Key  and Imports\n",
    "First, we need to import the necessary libraries and set up the OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-ft*****\n"
     ]
    }
   ],
   "source": [
    "# Setting Up OpenAI API\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']  # Replace with your actual API key\n",
    "\n",
    "# Print OpenAI API key (masked)\n",
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')[:5]}*****\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd554c8",
   "metadata": {},
   "source": [
    "**Note** Ensure you have the required packages installed:\n",
    "```py\n",
    "%pip install rich\n",
    "```\n",
    "The rich library helps to improve the readability of nested dictionary outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3d3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules from rich\n",
    "from rich import print\n",
    "from rich.pretty import Pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e3f7f",
   "metadata": {},
   "source": [
    "## Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ef5f9",
   "metadata": {},
   "source": [
    "### Example: Getting Current Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf3bd3",
   "metadata": {},
   "source": [
    "We will use an example of getting the current weather to demonstrate function calling. This is a good example because it involves external data that the language model can't generate on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dcffce",
   "metadata": {},
   "source": [
    "#### Define the Function for OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for OpenAI API\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990140b",
   "metadata": {},
   "source": [
    "#### Example User Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Amsterdam?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d9eb6",
   "metadata": {},
   "source": [
    "#### Call the ChatCompletion Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a8926c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD93iIuf9pyL6BsnmhijpTQXcFLj'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FunctionCall</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"location\":\"Amsterdam\"}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_current_weather'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675245</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD93iIuf9pyL6BsnmhijpTQXcFLj'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'function_call'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[1;35mFunctionCall\u001b[0m\u001b[1m(\u001b[0m\u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"location\":\"Amsterdam\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'get_current_weather'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675245\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m17\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m82\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m99\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d971179",
   "metadata": {},
   "source": [
    "**Explanation output** This output represents a response from OpenAI's GPT-3.5-Turbo model. The model was prompted with a message, and its response includes a function call to get_current_weather with the argument {\"location\":\"Amsterdam\"}. The response indicates that the `assistant decided to call the function instead of generating text content. The response includes metadata such as the model used, creation time, and token usage details`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f994411c",
   "metadata": {},
   "source": [
    "#### Access the Message Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205c434",
   "metadata": {},
   "source": [
    "To access response as an object, we need to use `dot notation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a700da3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FunctionCall</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"location\":\"Amsterdam\"}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_current_weather'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "    \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfunction_call\u001b[0m=\u001b[1;35mFunctionCall\u001b[0m\u001b[1m(\u001b[0m\u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"location\":\"Amsterdam\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'get_current_weather'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the content from the response\n",
    "response_message = response.choices[0].message\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c69a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"chatcmpl-AxD93iIuf9pyL6BsnmhijpTQXcFLj\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"choices\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"finish_reason\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"function_call\"</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"index\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"logprobs\"</span>: null,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"message\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"content\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"refusal\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"role\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"assistant\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"audio\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"function_call\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"arguments\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"{\\\"location\\\":\\\"Amsterdam\\\"}\"</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"get_current_weather\"</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"tool_calls\"</span>: null\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"created\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675245</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"model\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt-3.5-turbo-0125\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"object\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"chat.completion\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"service_tier\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"system_fingerprint\"</span>: null,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"usage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"completion_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"total_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"completion_tokens_details\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"accepted_prediction_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"audio_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"reasoning_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"rejected_prediction_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_tokens_details\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"audio_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"cached_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"id\"\u001b[0m: \u001b[32m\"chatcmpl-AxD93iIuf9pyL6BsnmhijpTQXcFLj\"\u001b[0m,\n",
       "    \u001b[32m\"choices\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"finish_reason\"\u001b[0m: \u001b[32m\"function_call\"\u001b[0m,\n",
       "            \u001b[32m\"index\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"logprobs\"\u001b[0m: null,\n",
       "            \u001b[32m\"message\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"content\"\u001b[0m: null,\n",
       "                \u001b[32m\"refusal\"\u001b[0m: null,\n",
       "                \u001b[32m\"role\"\u001b[0m: \u001b[32m\"assistant\"\u001b[0m,\n",
       "                \u001b[32m\"audio\"\u001b[0m: null,\n",
       "                \u001b[32m\"function_call\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m\"arguments\"\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\"location\\\":\\\"Amsterdam\\\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m,\n",
       "                    \u001b[32m\"name\"\u001b[0m: \u001b[32m\"get_current_weather\"\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m\"tool_calls\"\u001b[0m: null\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m\"created\"\u001b[0m: \u001b[1;36m1738675245\u001b[0m,\n",
       "    \u001b[32m\"model\"\u001b[0m: \u001b[32m\"gpt-3.5-turbo-0125\"\u001b[0m,\n",
       "    \u001b[32m\"object\"\u001b[0m: \u001b[32m\"chat.completion\"\u001b[0m,\n",
       "    \u001b[32m\"service_tier\"\u001b[0m: \u001b[32m\"default\"\u001b[0m,\n",
       "    \u001b[32m\"system_fingerprint\"\u001b[0m: null,\n",
       "    \u001b[32m\"usage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"completion_tokens\"\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "        \u001b[32m\"prompt_tokens\"\u001b[0m: \u001b[1;36m82\u001b[0m,\n",
       "        \u001b[32m\"total_tokens\"\u001b[0m: \u001b[1;36m99\u001b[0m,\n",
       "        \u001b[32m\"completion_tokens_details\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"accepted_prediction_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"audio_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"reasoning_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"rejected_prediction_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m\"prompt_tokens_details\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"audio_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"cached_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert response object to dictionary\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05b577",
   "metadata": {},
   "source": [
    "**Explanation output** This output is from an OpenAI GPT-3.5-Turbo model, indicating that it received a prompt and decided to make a function call. The specific function called is get_current_weather with the argument {\"location\":\"Amsterdam\"}. The response includes metadata such as the response ID, the model used, creation time, token usage, and details about the function call. `The message generated by the assistant does not contain direct content but initiates a function call to gather the required information.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38607e5",
   "metadata": {},
   "source": [
    "- Access the Message Content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db94496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the content from the response\n",
    "response_message = response.choices[0].message\n",
    "content = response_message.content  # Use dot notation\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073b1f3",
   "metadata": {},
   "source": [
    "#### Handling Function Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6441fd",
   "metadata": {},
   "source": [
    "- Handling Function Calls\n",
    "If the response contains a function call (as seen in the original output), content will be None, and you should `access the function details` instead:\n",
    "`response_message[\"function_call\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65638e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Function Name: get_current_weather\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Function Name: get_current_weather\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Arguments: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Arguments: \u001b[1m{\u001b[0m\u001b[32m\"location\"\u001b[0m:\u001b[32m\"Amsterdam\"\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if response_message.function_call:\n",
    "    function_name = response_message.function_call.name\n",
    "    function_args = response_message.function_call.arguments\n",
    "    print(f\"Function Name: {function_name}\")\n",
    "    print(f\"Arguments: {function_args}\")\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692a21e",
   "metadata": {},
   "source": [
    "#### Convert Response Object to a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ade065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'audio'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"location\":\"Amsterdam\"}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'get_current_weather'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'content'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "    \u001b[32m'audio'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'function_call'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"location\":\"Amsterdam\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'get_current_weather'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tool_calls'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert response object to a dictionary\n",
    "response_dict = response_message.model_dump()\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ca765",
   "metadata": {},
   "source": [
    "**Explanation output** This output represents part of a response from an AI assistant (role: \"assistant\") indicating that it has chosen to call a function rather than generate direct content. The function being called is `get_current_weather` with the argument `{\"location\":\"Amsterdam\"}`. The fields `content, refusal, audio, and tool_calls are null`, indicating that no textual content, refusal message, audio response, or tool calls were included in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d1647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Amsterdam'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'location'\u001b[0m: \u001b[32m'Amsterdam'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Access function call details using dot notation\n",
    "arguments_json = response_message.function_call.arguments  # This is already a string\n",
    "\n",
    "# Parse JSON string into a Python dictionary\n",
    "arguments_dict = json.loads(arguments_json)\n",
    "\n",
    "print(arguments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d9372-4388-4f18-b44c-e291668ea46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON string in the 'arguments' field of the function_call attribute of the response_message object into a Python dictionary.\n",
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d311",
   "metadata": {},
   "source": [
    "* Pass a message that is not related to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4346bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD947YJbkET5KKzL6HOZoDakbM4c'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello! How can I assist you today?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675246</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD947YJbkET5KKzL6HOZoDakbM4c'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Hello! How can I assist you today?'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675246\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m11\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m76\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m87\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aae46",
   "metadata": {},
   "source": [
    "* Pass additional parameters to force the model to use or not a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6e86d",
   "metadata": {},
   "source": [
    "#### Pass a Message Not Related to a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17edba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD95wvjMP6xVHmBTY8Aii2Mex9h3'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello! How can I assist you today?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675247</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD95wvjMP6xVHmBTY8Aii2Mex9h3'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Hello! How can I assist you today?'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675247\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m11\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m76\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m87\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284088e9",
   "metadata": {},
   "source": [
    "* Use mode 'none' for function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867dccb9",
   "metadata": {},
   "source": [
    "#### Call the ChatCompletion Endpoint for Non-Function Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cde66343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD95J3zxxgqEXvRFKJVJXZfKEW1r'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello! How can I assist you today?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675247</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD95J3zxxgqEXvRFKJVJXZfKEW1r'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Hello! How can I assist you today?'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675247\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m10\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m77\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m87\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05a76e",
   "metadata": {},
   "source": [
    "* When the message should call a function and still uses mode 'none'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40311744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD96YfH1skAhKOPTmSHHupGiLc0H'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I can look up the current weather in Amsterdam for you. Just give me a moment to retrieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the information.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675248</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD96YfH1skAhKOPTmSHHupGiLc0H'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'I can look up the current weather in Amsterdam for you. Just give me a moment to retrieve \u001b[0m\n",
       "\u001b[32mthe information.'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675248\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m23\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m82\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m105\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in Amsterdam?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38735d9f",
   "metadata": {},
   "source": [
    "* Force calling a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24e0749a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD97gslaZEZetUvFv9UE4tzFU5oS'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FunctionCall</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"location\":\"San Francisco, CA\",\"unit\":\"celsius\"}'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_current_weather'</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675249</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD97gslaZEZetUvFv9UE4tzFU5oS'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[1;35mFunctionCall\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"location\":\"San Francisco, CA\",\"unit\":\"celsius\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                    \u001b[33mname\u001b[0m=\u001b[32m'get_current_weather'\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675249\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m14\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m86\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m100\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27abbdc",
   "metadata": {},
   "source": [
    "* Final notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3062eab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AxD97uaGLxf7QkZ4UWUIfOA7L5dun'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FunctionCall</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"location\":\"Amsterdam\"}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_current_weather'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675249</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AxD97uaGLxf7QkZ4UWUIfOA7L5dun'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[1;35mFunctionCall\u001b[0m\u001b[1m(\u001b[0m\u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"location\":\"Amsterdam\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'get_current_weather'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1738675249\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m7\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m92\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m99\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Amsterdam!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc2e1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content from the response\n",
    "messages.append(response.choices[0].message)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "579cc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response.choices[0].message.function_call.arguments)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94886508",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = get_current_weather(args)  # Assuming `get_current_weather` is properly defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa1e07ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"temperature\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"72\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"unit\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"fahrenheit\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"forecast\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"sunny\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"windy\"</span><span style=\"font-weight: bold\">]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m\"location\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"location\"\u001b[0m: \u001b[32m\"Amsterdam\"\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m\"temperature\"\u001b[0m: \u001b[32m\"72\"\u001b[0m, \u001b[32m\"unit\"\u001b[0m: \u001b[32m\"fahrenheit\"\u001b[0m, \u001b[32m\"forecast\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"sunny\"\u001b[0m, \u001b[32m\"windy\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    args = json.loads(response_message.function_call.arguments)  # Convert JSON string to dictionary\n",
    "    observation = get_current_weather(args)  # Call the function with extracted arguments\n",
    "    print(observation)\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f05f3",
   "metadata": {},
   "source": [
    "**Explanation output** This output represents weather information for the location \"Amsterdam.\" It includes the current temperature of 72 degrees Fahrenheit and a weather forecast indicating \"sunny\" and \"windy\" conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360f47b",
   "metadata": {},
   "source": [
    "- Final Fixed & Formatted Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5061a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŸ¢ Function Call Detected:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŸ¢ Function Call Detected:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”¹ Function Name: get_current_weather\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”¹ Function Name: get_current_weather\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”¹ Arguments: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”¹ Arguments: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"location\"\u001b[0m: \u001b[32m\"Amsterdam\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŒ¦ï¸ Weather Observation Result:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŒ¦ï¸ Weather Observation Result:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"{\\\"location\\\": {\\\"location\\\": \\\"Amsterdam\\\"}, \\\"temperature\\\": \\\"72\\\", \\\"unit\\\": \\\"fahrenheit\\\", \\\"forecast\\\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">[\\\"sunny\\\", \\\"windy\\\"]}\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\"location\\\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\"location\\\": \\\"Amsterdam\\\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \\\"temperature\\\": \\\"72\\\", \\\"unit\\\": \\\"fahrenheit\\\", \\\"forecast\\\": \u001b[0m\n",
       "\u001b[32m[\u001b[0m\u001b[32m\\\"sunny\\\", \\\"windy\\\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Pretty-print the output\n",
    "    print(\"\\nðŸŸ¢ Function Call Detected:\")\n",
    "    print(f\"ðŸ”¹ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"ðŸ”¹ Arguments: {json.dumps(args, indent=4)}\")  # Pretty print JSON arguments\n",
    "    print(\"\\nðŸŒ¦ï¸ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))  # Assuming the function returns a dictionary\n",
    "else:\n",
    "    print(\"\\nðŸ’¬ Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da38562",
   "metadata": {},
   "source": [
    "If the assistant calls get_current_weather with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9dc4551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŸ¢ Function Call Detected:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŸ¢ Function Call Detected:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”¹ Function Name: get_current_weather\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”¹ Function Name: get_current_weather\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”¹ Arguments: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”¹ Arguments: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"location\"\u001b[0m: \u001b[32m\"Amsterdam\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŒ¦ï¸ Weather Observation Result:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŒ¦ï¸ Weather Observation Result:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"temperature\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"72\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"unit\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"fahrenheit\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"forecast\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"sunny\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"windy\"</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"location\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"location\"\u001b[0m: \u001b[32m\"Amsterdam\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m\"temperature\"\u001b[0m: \u001b[32m\"72\"\u001b[0m,\n",
       "    \u001b[32m\"unit\"\u001b[0m: \u001b[32m\"fahrenheit\"\u001b[0m,\n",
       "    \u001b[32m\"forecast\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m\"sunny\"\u001b[0m,\n",
       "        \u001b[32m\"windy\"\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure `observation` is a dictionary, not a string\n",
    "    if isinstance(observation, str):\n",
    "        observation = json.loads(observation)\n",
    "\n",
    "    # Pretty-print the function call details\n",
    "    print(\"\\nðŸŸ¢ Function Call Detected:\")\n",
    "    print(f\"ðŸ”¹ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"ðŸ”¹ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\nðŸŒ¦ï¸ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nðŸ’¬ Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63454808-10a2-4301-9977-89aa79018152",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91f5c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure observation is a properly formatted string\n",
    "if isinstance(observation, dict):\n",
    "    observation_str = json.dumps(observation)  # Convert dictionary to JSON string\n",
    "else:\n",
    "    observation_str = observation  # If already a string, use as-is\n",
    "\n",
    "# Append the function result to the messages list\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"content\": observation_str,  # Now a properly formatted string\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2664659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸ’¬ Assistant Response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸ’¬ Assistant Response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I currently do not have real-time information on weather. I recommend checking a weather website or app for the \n",
       "most up-to-date weather information in Amsterdam.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "I currently do not have real-time information on weather. I recommend checking a weather website or app for the \n",
       "most up-to-date weather information in Amsterdam.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸ”µ Final OpenAI Response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸ”µ Final OpenAI Response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"chatcmpl-AxD9Bp1LtmShigBQl6GpfodtjpwO8\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"choices\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"finish_reason\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"stop\"</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"index\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"logprobs\"</span>: null,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"message\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"content\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I'm sorry, but I am not able to provide real-time weather information. I recommend </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">checking a reliable weather website or using a weather app on your phone for the most up-to-date information on the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">weather in Amsterdam.\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"refusal\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"role\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"assistant\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"audio\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"function_call\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"tool_calls\"</span>: null\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"created\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675253</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"model\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt-3.5-turbo-0125\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"object\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"chat.completion\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"service_tier\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"system_fingerprint\"</span>: null,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"usage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"completion_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"total_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"completion_tokens_details\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"accepted_prediction_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"audio_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"reasoning_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"rejected_prediction_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_tokens_details\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"audio_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"cached_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"id\"\u001b[0m: \u001b[32m\"chatcmpl-AxD9Bp1LtmShigBQl6GpfodtjpwO8\"\u001b[0m,\n",
       "    \u001b[32m\"choices\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"finish_reason\"\u001b[0m: \u001b[32m\"stop\"\u001b[0m,\n",
       "            \u001b[32m\"index\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"logprobs\"\u001b[0m: null,\n",
       "            \u001b[32m\"message\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"content\"\u001b[0m: \u001b[32m\"I'm sorry, but I am not able to provide real-time weather information. I recommend \u001b[0m\n",
       "\u001b[32mchecking a reliable weather website or using a weather app on your phone for the most up-to-date information on the\u001b[0m\n",
       "\u001b[32mweather in Amsterdam.\"\u001b[0m,\n",
       "                \u001b[32m\"refusal\"\u001b[0m: null,\n",
       "                \u001b[32m\"role\"\u001b[0m: \u001b[32m\"assistant\"\u001b[0m,\n",
       "                \u001b[32m\"audio\"\u001b[0m: null,\n",
       "                \u001b[32m\"function_call\"\u001b[0m: null,\n",
       "                \u001b[32m\"tool_calls\"\u001b[0m: null\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m\"created\"\u001b[0m: \u001b[1;36m1738675253\u001b[0m,\n",
       "    \u001b[32m\"model\"\u001b[0m: \u001b[32m\"gpt-3.5-turbo-0125\"\u001b[0m,\n",
       "    \u001b[32m\"object\"\u001b[0m: \u001b[32m\"chat.completion\"\u001b[0m,\n",
       "    \u001b[32m\"service_tier\"\u001b[0m: \u001b[32m\"default\"\u001b[0m,\n",
       "    \u001b[32m\"system_fingerprint\"\u001b[0m: null,\n",
       "    \u001b[32m\"usage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"completion_tokens\"\u001b[0m: \u001b[1;36m45\u001b[0m,\n",
       "        \u001b[32m\"prompt_tokens\"\u001b[0m: \u001b[1;36m25\u001b[0m,\n",
       "        \u001b[32m\"total_tokens\"\u001b[0m: \u001b[1;36m70\u001b[0m,\n",
       "        \u001b[32m\"completion_tokens_details\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"accepted_prediction_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"audio_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"reasoning_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"rejected_prediction_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m\"prompt_tokens_details\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"audio_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"cached_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize OpenAI client (replace with your actual API key)\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Existing messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Amsterdam?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API to get response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)  # Convert dict to JSON string\n",
    "    else:\n",
    "        observation_str = str(observation)  # Ensure it's a string\n",
    "\n",
    "    # Append the function result back to the conversation history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,  # âœ… Now always a string\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nðŸŸ¢ Function Call Detected:\")\n",
    "    print(f\"ðŸ”¹ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"ðŸ”¹ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Convert observation back to a dictionary if needed for pretty-printing\n",
    "    if isinstance(observation_str, str):\n",
    "        observation = json.loads(observation_str)\n",
    "\n",
    "    # Print formatted weather observation\n",
    "    print(\"\\nðŸŒ¦ï¸ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nðŸ’¬ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nðŸ”µ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388276b",
   "metadata": {},
   "source": [
    "**Explantion output** The issue is that the assistant is not calling the function (get_current_weather). Instead, it is giving a default response, `saying it does not have real-time information`.\n",
    "ðŸ”¹ Why Is This Happening?  \n",
    "- The assistant isnâ€™t aware that it can call a function.  \n",
    "- You need to explicitly define functions in your request to OpenAI.  \n",
    "- No function definition was provided to OpenAI's API.  \n",
    "- You must include functions in client.chat.completions.create().  \n",
    "- function_call behavior isnâ€™t specified.  \n",
    "- OpenAI wonâ€™t automatically call a function unless you tell it to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36d780",
   "metadata": {},
   "source": [
    "#### âœ… Final Fixed & Optimized Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17143c1d",
   "metadata": {},
   "source": [
    "Let's fix the above code in order to get a significant response from the assistent. Thus, in this case, get an answer about the actual weather in Amsterdam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2544bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŸ¢ Function Call Detected:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŸ¢ Function Call Detected:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”¹ Function Name: get_current_weather\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”¹ Function Name: get_current_weather\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”¹ Arguments: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"unit\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"celsius\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”¹ Arguments: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"location\"\u001b[0m: \u001b[32m\"Amsterdam\"\u001b[0m,\n",
       "    \u001b[32m\"unit\"\u001b[0m: \u001b[32m\"celsius\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŒ¦ï¸ Weather Observation Result:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŒ¦ï¸ Weather Observation Result:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"location\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Amsterdam\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"unit\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"celsius\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"temperature\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"72\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"unit\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"fahrenheit\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"forecast\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"sunny\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"windy\"</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"location\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"location\"\u001b[0m: \u001b[32m\"Amsterdam\"\u001b[0m,\n",
       "        \u001b[32m\"unit\"\u001b[0m: \u001b[32m\"celsius\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m\"temperature\"\u001b[0m: \u001b[32m\"72\"\u001b[0m,\n",
       "    \u001b[32m\"unit\"\u001b[0m: \u001b[32m\"fahrenheit\"\u001b[0m,\n",
       "    \u001b[32m\"forecast\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m\"sunny\"\u001b[0m,\n",
       "        \u001b[32m\"windy\"\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸ”µ Final OpenAI Response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸ”µ Final OpenAI Response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"chatcmpl-AxD9DjeipyzaTkCcc819VmUeENV4d\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"choices\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"finish_reason\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"stop\"</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"index\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"logprobs\"</span>: null,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"message\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"content\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The current weather in Amsterdam is 72\\u00b0F with sunny and windy conditions.\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"refusal\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"role\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"assistant\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"audio\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"function_call\"</span>: null,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"tool_calls\"</span>: null\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"created\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1738675255</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"model\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt-3.5-turbo-0125\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"object\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"chat.completion\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"service_tier\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"system_fingerprint\"</span>: null,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"usage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"completion_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">137</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"total_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">154</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"completion_tokens_details\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"accepted_prediction_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"audio_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"reasoning_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"rejected_prediction_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_tokens_details\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"audio_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"cached_tokens\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"id\"\u001b[0m: \u001b[32m\"chatcmpl-AxD9DjeipyzaTkCcc819VmUeENV4d\"\u001b[0m,\n",
       "    \u001b[32m\"choices\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"finish_reason\"\u001b[0m: \u001b[32m\"stop\"\u001b[0m,\n",
       "            \u001b[32m\"index\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"logprobs\"\u001b[0m: null,\n",
       "            \u001b[32m\"message\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"content\"\u001b[0m: \u001b[32m\"The current weather in Amsterdam is 72\\u00b0F with sunny and windy conditions.\"\u001b[0m,\n",
       "                \u001b[32m\"refusal\"\u001b[0m: null,\n",
       "                \u001b[32m\"role\"\u001b[0m: \u001b[32m\"assistant\"\u001b[0m,\n",
       "                \u001b[32m\"audio\"\u001b[0m: null,\n",
       "                \u001b[32m\"function_call\"\u001b[0m: null,\n",
       "                \u001b[32m\"tool_calls\"\u001b[0m: null\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m\"created\"\u001b[0m: \u001b[1;36m1738675255\u001b[0m,\n",
       "    \u001b[32m\"model\"\u001b[0m: \u001b[32m\"gpt-3.5-turbo-0125\"\u001b[0m,\n",
       "    \u001b[32m\"object\"\u001b[0m: \u001b[32m\"chat.completion\"\u001b[0m,\n",
       "    \u001b[32m\"service_tier\"\u001b[0m: \u001b[32m\"default\"\u001b[0m,\n",
       "    \u001b[32m\"system_fingerprint\"\u001b[0m: null,\n",
       "    \u001b[32m\"usage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"completion_tokens\"\u001b[0m: \u001b[1;36m17\u001b[0m,\n",
       "        \u001b[32m\"prompt_tokens\"\u001b[0m: \u001b[1;36m137\u001b[0m,\n",
       "        \u001b[32m\"total_tokens\"\u001b[0m: \u001b[1;36m154\u001b[0m,\n",
       "        \u001b[32m\"completion_tokens_details\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"accepted_prediction_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"audio_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"reasoning_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"rejected_prediction_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m\"prompt_tokens_details\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"audio_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m\"cached_tokens\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Define the function OpenAI can call\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g., 'Boston'\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Amsterdam?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API with function definition\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # âœ… Add function definition\n",
    "    function_call=\"auto\"  # âœ… Force the model to call a function if needed\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)\n",
    "    else:\n",
    "        observation_str = str(observation)\n",
    "\n",
    "    # Append function response back to messages\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\nðŸŸ¢ Function Call Detected:\")\n",
    "    print(f\"ðŸ”¹ Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"ðŸ”¹ Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\nðŸŒ¦ï¸ Weather Observation Result:\")\n",
    "    print(json.dumps(json.loads(observation_str), indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\nðŸ’¬ Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages to continue the conversation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # âœ… Keep functions defined for future calls\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\nðŸ”µ Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122a720",
   "metadata": {},
   "source": [
    "**Explanation output** To sum up, now, `the assistent gives the right answer`, thus info about the actual weather in Amsterdam. Thus, the final OpenAI Response: \"message\":   {\"content\": \"The current weather in Amsterdam is 22\\u00b0C (72\\u00b0F) with sunny and windy`}. What it has been fixed and optimized, compared to pthe previous output, has been: \n",
    "- Uses dot notation instead of response[\"choices\"][0][\"message\"]  \n",
    "- Ensures observation is properly formatted (json.dumps(observation))  \n",
    "- Handles function calls correctly  \n",
    "- Prints a structured, readable response  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71b4b8-3a1c-4c19-9d65-d50340207dca",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrates how to integrate OpenAI's function calling capabilities using the updated GPT-3.5-Turbo model. By following these examples, you can effectively utilize the latest OpenAI API changes in your projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
