{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3df44d6-62d0-4324-8052-419503a6b040",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b038f2-759a-42e9-ab02-eca264b93ee5",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- OpenAI has announced the release of an updated GPT-3.5-Turbo model and the deprecation of the ```gpt-3.5-turbo-0613``` model. The gpt-3.5-turbo-0613 model, which has been utilized in this Short Course since its launch in October 2023, will be replaced by the ```gpt-3.5-turbo``` model. > Note: This notebook was updated in June 2024. Consequently, we are now using the ```gpt-3.5-turbo model``` instead of the ```gpt-3.5-turbo-0613``` model featured by the instructor in the video lesson.\n",
    "- The `openai.ChatCompletion.create` has been removed in OpenAI's Python client version 1.0.0 and later. The API has changed, and here it has been update the code to use the new format.  \n",
    "✅ Solution: Update the Code to Use the New API  \n",
    "In OpenAI's latest API, `ChatCompletion.create` is replaced by `openai.ChatCompletion.create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f8d9dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-ftrE5R1SUdZBr8XxRi3rtI4F5g2i47i67FfUv9AXmjT3BlbkFJqODP02vVsRNjuVbRKIfFInuuWKeXKv_SqGGoIUNokA\n"
     ]
    }
   ],
   "source": [
    "print(f\"OPENAI_API_KEY: {os.getenv('OPENAI_API_KEY')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555e832",
   "metadata": {},
   "source": [
    "We will use as example `getting the current weather` because this is a good example because is something that the language model can't neccessary do it self. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather like in Boston?\"\n",
    "        \"content\": \"What's the weather like in Amsterdam?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654fce05-7ef6-49d7-8d78-f190ecf3f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ChatCompletion endpoint\n",
    "#response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "    #functions=functions\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2a8926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None))], created=1738311875, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=82, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "#import openai\n",
    "#import os\n",
    "\n",
    "# Ensure you are using the correct client initialization\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5808587",
   "metadata": {},
   "source": [
    "Let's get format of the above output in a cleaner and more readable way using json.dumps(). To do this,   we need to convert the response to a dictionary first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f940206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311875,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_message = response[\"choices\"][0][\"message\"]\n",
    "#print(response_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472da20",
   "metadata": {},
   "source": [
    "**Explanation output** The error message TypeError: 'ChatCompletion' object is not subscriptable means that response is an object, not a dictionary. To `get access response as a Object` we should `use dot notation (response.choices[0].message) instead of dictionary-style indexing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a700da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74c69a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgcFsHMWYLN5Q5f23mS23TdJBfx0\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311875,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "# Convert response object to dictionary\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38607e5",
   "metadata": {},
   "source": [
    "- Access the Message Content  \n",
    "`response_message[\"content\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3db94496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Extract the content from the response\n",
    "response_message = response.choices[0].message\n",
    "content = response_message.content  # Use dot notation\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6441fd",
   "metadata": {},
   "source": [
    "- Handling Function Calls\n",
    "If the response contains a function call (as seen in your original output), content will be None, and you should `access the function details` instead:\n",
    "`response_message[\"function_call\"] has been replaced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65638e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: get_current_weather\n",
      "Arguments: {\"location\":\"Amsterdam\"}\n"
     ]
    }
   ],
   "source": [
    "if response_message.function_call:\n",
    "    function_name = response_message.function_call.name\n",
    "    function_args = response_message.function_call.arguments\n",
    "    print(f\"Function Name: {function_name}\")\n",
    "    print(f\"Arguments: {function_args}\")\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6ade065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"audio\": null,\n",
      "    \"function_call\": {\n",
      "        \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "        \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"tool_calls\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert response object to a dictionary\n",
    "response_dict = response_message.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "formatted_response = json.dumps(response_dict, indent=4)\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b90cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "# Convert response object to a dictionary\n",
    "#response_dict = response.model_dump()\n",
    "\n",
    "# Pretty print\n",
    "#formatted_response = json.dumps(response_dict, indent=4)\n",
    "#print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "433a51b6-9c92-4765-85aa-285dccf7748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "#args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "#get_current_weather(args)\n",
    "\n",
    "#  Use dot notation: response_message.content instead of response_message[\"content\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f0d1647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Amsterdam'}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "\n",
    "# Access function call details using dot notation\n",
    "arguments_json = response_message.function_call.arguments  # This is already a string\n",
    "\n",
    "# Parse JSON string into a Python dictionary\n",
    "arguments_dict = json.loads(arguments_json)\n",
    "\n",
    "print(arguments_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "675d9372-4388-4f18-b44c-e291668ea46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d311",
   "metadata": {},
   "source": [
    "* Pass a message that is not related to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8300232d-4f02-478b-bba2-d47173422866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "    #functions=functions,\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d4346bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgdOSFWGeXAOsU5lKhB25BdhjPIJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311946, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=76, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions  # If you're using function calling\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b27cebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgdOSFWGeXAOsU5lKhB25BdhjPIJ\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311946,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 11,\n",
      "        \"prompt_tokens\": 76,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aae46",
   "metadata": {},
   "source": [
    "* Pass additional parameters to force the model to use or not a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2af9f72-1cb9-4a97-b030-22562ecab99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages = [\n",
    "    #{\n",
    "        #\"role\": \"user\",\n",
    "        #\"content\": \"hi!\",\n",
    "    #}\n",
    "#]\n",
    "#response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "    #functions=functions,\n",
    "    #function_call=\"auto\",\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17edba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgdcXz7QjB0TwqBdNhLGgbgdYYRF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311960, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=76, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "123f1cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgdcXz7QjB0TwqBdNhLGgbgdYYRF\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311960,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 11,\n",
      "        \"prompt_tokens\": 76,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284088e9",
   "metadata": {},
   "source": [
    "* Use mode 'none' for function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8cafc-f785-4595-9e3c-48b06424ee8b",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cde66343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Avgdo3xdNARN2uzWJPKb7mNNmEpFE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311972, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=77, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19c931ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-Avgdo3xdNARN2uzWJPKb7mNNmEpFE\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Hello! How can I assist you today?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311972,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 10,\n",
      "        \"prompt_tokens\": 77,\n",
      "        \"total_tokens\": 87,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05a76e",
   "metadata": {},
   "source": [
    "* When the message should call a function and still uses mode 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7cc5a7-1572-4171-9016-9ec2871d389b",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in Boston?\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40311744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Avge0TYjc5gMaAKC9xz9cLTiqN08c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sure, let me check that for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738311984, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=82, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather in Boston?\",\n",
    "        \"content\": \"What's the weather in Amsterdam?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32ecc17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-Avge0TYjc5gMaAKC9xz9cLTiqN08c\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Sure, let me check that for you.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738311984,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 10,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 92,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38735d9f",
   "metadata": {},
   "source": [
    "* Force calling a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a92ba-5677-4c72-b556-d29e6a4152a0",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24e0749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgeHUKUjGs62bMDLr22UzID8tUze', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"San Francisco, CA\"}', name='get_current_weather'), tool_calls=None))], created=1738312001, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=86, total_tokens=95, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36d75289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgeHUKUjGs62bMDLr22UzID8tUze\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312001,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 9,\n",
      "        \"prompt_tokens\": 86,\n",
      "        \"total_tokens\": 95,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27abbdc",
   "metadata": {},
   "source": [
    "* Final notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5229a4-2700-48b4-b2b9-3b1e1535f903",
   "metadata": {},
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "response = openai.ChatCompletion.create(\n",
    "    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3062eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AvgeewkQWYL0xyG020vrnV99jSDsV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Amsterdam\"}', name='get_current_weather'), tool_calls=None))], created=1738312024, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=92, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        #\"content\": \"What's the weather like in Boston!\",\n",
    "        \"content\": \"What's the weather like in Amsterdam!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # If you're using function calling\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a5d1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AvgeewkQWYL0xyG020vrnV99jSDsV\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Amsterdam\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                },\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312024,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 92,\n",
      "        \"total_tokens\": 99,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-Print OpenAI ChatCompletion Response\n",
    "\n",
    "#import json\n",
    "# Convert response to a dictionary and pretty-print\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc2e1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content from the response\n",
    "messages.append(response.choices[0].message)  # ✅ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f3a9d7-9f30-4524-a952-5dd87c6d2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages.append(response[\"choices\"][0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c817376f-3a7f-4448-acdd-1639c70d42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = json.loads(response[\"choices\"][0][\"message\"]['function_call']['arguments'])\n",
    "#observation = get_current_weather(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "579cc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response.choices[0].message.function_call.arguments)  # ✅ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94886508",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = get_current_weather(args)  # Assuming `get_current_weather` is properly defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa1e07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"location\": {\"location\": \"Amsterdam\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    args = json.loads(response_message.function_call.arguments)  # Convert JSON string to dictionary\n",
    "    observation = get_current_weather(args)  # Call the function with extracted arguments\n",
    "    print(observation)\n",
    "else:\n",
    "    print(f\"Assistant Response: {response_message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360f47b",
   "metadata": {},
   "source": [
    "Final Fixed & Formatted Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5061a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟢 Function Call Detected:\n",
      "🔹 Function Name: get_current_weather\n",
      "🔹 Arguments: {\n",
      "    \"location\": \"Amsterdam\"\n",
      "}\n",
      "\n",
      "🌦️ Weather Observation Result:\n",
      "\"{\\\"location\\\": {\\\"location\\\": \\\"Amsterdam\\\"}, \\\"temperature\\\": \\\"72\\\", \\\"unit\\\": \\\"fahrenheit\\\", \\\"forecast\\\": [\\\"sunny\\\", \\\"windy\\\"]}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Pretty-print the output\n",
    "    print(\"\\n🟢 Function Call Detected:\")\n",
    "    print(f\"🔹 Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"🔹 Arguments: {json.dumps(args, indent=4)}\")  # Pretty print JSON arguments\n",
    "    print(\"\\n🌦️ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))  # Assuming the function returns a dictionary\n",
    "else:\n",
    "    print(\"\\n💬 Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da38562",
   "metadata": {},
   "source": [
    "If the assistant calls get_current_weather with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9dc4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟢 Function Call Detected:\n",
      "🔹 Function Name: get_current_weather\n",
      "🔹 Arguments: {\n",
      "    \"location\": \"Amsterdam\"\n",
      "}\n",
      "\n",
      "🌦️ Weather Observation Result:\n",
      "{\n",
      "    \"location\": {\n",
      "        \"location\": \"Amsterdam\"\n",
      "    },\n",
      "    \"temperature\": \"72\",\n",
      "    \"unit\": \"fahrenheit\",\n",
      "    \"forecast\": [\n",
      "        \"sunny\",\n",
      "        \"windy\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_message = response.choices[0].message  # Use dot notation\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Convert function call arguments (JSON string) to a Python dictionary\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Call the function with extracted arguments\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure `observation` is a dictionary, not a string\n",
    "    if isinstance(observation, str):\n",
    "        observation = json.loads(observation)\n",
    "\n",
    "    # Pretty-print the function call details\n",
    "    print(\"\\n🟢 Function Call Detected:\")\n",
    "    print(f\"🔹 Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"🔹 Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\n🌦️ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\n💬 Assistant Response:\")\n",
    "    print(response_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63454808-10a2-4301-9977-89aa79018152",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91f5c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Ensure observation is a properly formatted string\n",
    "if isinstance(observation, dict):\n",
    "    observation_str = json.dumps(observation)  # Convert dictionary to JSON string\n",
    "else:\n",
    "    observation_str = observation  # If already a string, use as-is\n",
    "\n",
    "# Append the function result to the messages list\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"content\": observation_str,  # Now a properly formatted string\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f323fb69-c907-4f19-a2d9-80d828b4a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = openai.ChatCompletion.create(\n",
    "   # model=\"gpt-3.5-turbo\",\n",
    "    #messages=messages,\n",
    "#)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cf475",
   "metadata": {},
   "source": [
    "# Call the ChatCompletion endpoint using the new API format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,  \n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb76cc",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "# Call the ChatCompletion endpoint\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,  \n",
    ")\n",
    "\n",
    "# Convert response to a dictionary and pretty-print it\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2664659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Assistant Response:\n",
      "I'm sorry, but I don't have real-time information on the current weather. You can check the weather in Boston by using a weather website or app like Weather.com or AccuWeather.\n",
      "\n",
      "🔵 Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvgfXUxC1BEPnPUCFpU9Sz7lsoj9T\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"I don't have real-time information, but you can check the current weather in Boston by visiting a weather website or using a weather app on your phone.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312079,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 32,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 57,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client (replace with your actual API key)\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Existing messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API to get response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)  # Convert dict to JSON string\n",
    "    else:\n",
    "        observation_str = str(observation)  # Ensure it's a string\n",
    "\n",
    "    # Append the function result back to the conversation history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,  # ✅ Now always a string\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\n🟢 Function Call Detected:\")\n",
    "    print(f\"🔹 Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"🔹 Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Convert observation back to a dictionary if needed for pretty-printing\n",
    "    if isinstance(observation_str, str):\n",
    "        observation = json.loads(observation_str)\n",
    "\n",
    "    # Print formatted weather observation\n",
    "    print(\"\\n🌦️ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\n💬 Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\n🔵 Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388276b",
   "metadata": {},
   "source": [
    "**Explantion output** issue is that the assistant is not calling the function (get_current_weather). Instead, it is giving a default response, saying it does not have real-time information.\n",
    "🔹 Why Is This Happening?\n",
    "The assistant isn’t aware that it can call a function.\n",
    "You need to explicitly define functions in your request to OpenAI.\n",
    "No function definition was provided to OpenAI's API.\n",
    "You must include functions in client.chat.completions.create().\n",
    "function_call behavior isn’t specified.\n",
    "OpenAI won’t automatically call a function unless you tell it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2544bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟢 Function Call Detected:\n",
      "🔹 Function Name: get_current_weather\n",
      "🔹 Arguments: {\n",
      "    \"location\": \"Amsterdam\",\n",
      "    \"unit\": \"celsius\"\n",
      "}\n",
      "\n",
      "🌦️ Weather Observation Result:\n",
      "{\n",
      "    \"location\": {\n",
      "        \"location\": \"Amsterdam\",\n",
      "        \"unit\": \"celsius\"\n",
      "    },\n",
      "    \"temperature\": \"72\",\n",
      "    \"unit\": \"fahrenheit\",\n",
      "    \"forecast\": [\n",
      "        \"sunny\",\n",
      "        \"windy\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "🔵 Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvgfzNg8jGdCmelUs4f4gZHzpgoTd\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"The current weather in Amsterdam is 22\\u00b0C (72\\u00b0F) with sunny and windy conditions.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312107,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 21,\n",
      "        \"prompt_tokens\": 137,\n",
      "        \"total_tokens\": 158,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Define the function OpenAI can call\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g., 'Boston'\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Amsterdam?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API with function definition\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # ✅ Add function definition\n",
    "    function_call=\"auto\"  # ✅ Force the model to call a function if needed\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)\n",
    "    else:\n",
    "        observation_str = str(observation)\n",
    "\n",
    "    # Append function response back to messages\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\n🟢 Function Call Detected:\")\n",
    "    print(f\"🔹 Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"🔹 Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Pretty-print the weather observation\n",
    "    print(\"\\n🌦️ Weather Observation Result:\")\n",
    "    print(json.dumps(json.loads(observation_str), indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\n💬 Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages to continue the conversation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,  # ✅ Keep functions defined for future calls\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\n🔵 Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8cbe3b",
   "metadata": {},
   "source": [
    "✅ Final Fixed & Optimized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf4bedc6-6342-4d69-9e19-181d2b0aa243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Assistant Response:\n",
      "I'm sorry, but I cannot provide real-time weather information. You can check the weather in Boston by using a weather app on your smartphone or by visiting a reliable weather website.\n",
      "\n",
      "🔵 Final OpenAI Response:\n",
      "{\n",
      "    \"id\": \"chatcmpl-AvggVzh5e5abBhGkc9hQtnfOkEhp3\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"I'm sorry, but I do not have real-time information on the current weather conditions. You can check the weather in Boston by visiting a reliable weather website or using a weather app on your phone.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1738312139,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 41,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 66,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client (replace with your actual API key)\n",
    "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])  # Replace with your actual API key\n",
    "\n",
    "# Existing messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "# Call OpenAI API to get response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Extract the assistant's response\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response_message.function_call:\n",
    "    # Extract and parse function call arguments\n",
    "    args = json.loads(response_message.function_call.arguments)\n",
    "    \n",
    "    # Simulating the function call (replace with real implementation)\n",
    "    observation = get_current_weather(args)\n",
    "\n",
    "    # Ensure observation is a JSON string before appending to messages\n",
    "    if isinstance(observation, dict):\n",
    "        observation_str = json.dumps(observation)  # Convert dict to JSON string\n",
    "    else:\n",
    "        observation_str = observation  # If already a string, use as-is\n",
    "\n",
    "    # Append the function result back to the conversation history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation_str,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print formatted function call details\n",
    "    print(\"\\n🟢 Function Call Detected:\")\n",
    "    print(f\"🔹 Function Name: {response_message.function_call.name}\")\n",
    "    print(f\"🔹 Arguments: {json.dumps(args, indent=4)}\")\n",
    "\n",
    "    # Convert observation back to a dictionary if needed for pretty-printing\n",
    "    if isinstance(observation_str, str):\n",
    "        observation = json.loads(observation_str)\n",
    "\n",
    "    # Print formatted weather observation\n",
    "    print(\"\\n🌦️ Weather Observation Result:\")\n",
    "    print(json.dumps(observation, indent=4))\n",
    "\n",
    "else:\n",
    "    print(\"\\n💬 Assistant Response:\")\n",
    "    print(response_message.content)\n",
    "\n",
    "# Call OpenAI API again with updated messages\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Pretty-print the final OpenAI response\n",
    "formatted_response = json.dumps(response.model_dump(), indent=4)\n",
    "print(\"\\n🔵 Final OpenAI Response:\")\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad839a6-83e9-46a2-9d39-d7be8cbcc6f8",
   "metadata": {},
   "source": [
    "🔹 What’s Fixed & Optimized?\n",
    "✅ Uses dot notation instead of response[\"choices\"][0][\"message\"]\n",
    "✅ Ensures observation is properly formatted (json.dumps(observation))\n",
    "✅ Handles function calls correctly\n",
    "✅ Prints a structured, readable response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71b4b8-3a1c-4c19-9d65-d50340207dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98ceb2-0feb-49c6-9889-70e9b52300e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec827289-00c7-444e-aeb2-1e7404fbc15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd3cb6-a782-427a-bd34-46ce47e5f707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef7189-688b-4d79-b11b-67b147a00352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6733b4e-a958-421c-a3c8-635e91428f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4ecd5-14c1-492e-84ec-b4f6bb508e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e262ae6-092b-4f9e-a1cc-cc1704ecfe76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc5cd3-84f4-4d05-b941-575cafd3e14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca8690-50b3-42dc-b95c-364bbcd14581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e64656-d3ee-47a5-96e0-766652f28138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27659fe-3720-4e13-83d0-fe2d52b03075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c16168-2988-4540-a921-b78e299ab5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1d9ed-fb4e-4f3f-a8df-4a6d67c3ec1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed11cb-5a90-49a5-aecb-48081d146af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f0256-9cb4-4f3b-8614-0b69a4eeaac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442de8e-ad55-4730-a43b-0c2bc2066b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854155b-57f8-49f2-b595-6b6163d9db2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8637d7d-d6cc-4c55-b3cc-8dc51a35efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a450da3-ef87-44f7-872c-39a1a714a015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd24043-91e6-4838-8ce0-7f02802cf62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63167545-4805-4534-a8c0-9e3161edc02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5a420-9c52-441c-b868-6ce69c498477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab51675-a078-4704-b63b-9f722d86b0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c2a24-c011-4c44-a78e-611143ff3034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600778a5-a4d5-44aa-b3a7-172c82e74eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60557042-93b5-4172-8aaa-1219ea35addb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f24b4-0796-4c2d-86ab-0d23766551d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611029f7-e4c5-45b0-bcc9-9ec214a32686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ed315-b80a-4d82-bda8-41cc54b30b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be374e72-c849-4962-bb50-33607824bab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7702f2-cee6-4649-a662-6d1dc9d49e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2ba14-9908-48b1-adad-1ef764114254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
