{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9690ac72-5d95-4cbf-875a-ae0e835593c9",
   "metadata": {},
   "source": [
    "# Simple ReAct Agent from Scratch\n",
    "\n",
    "## Introduction \n",
    "In this notebook, we will `build a simple ReAct (Retrieval-Augmented Generation) agent from scratch using the OpenAI API`. The agent will be able to process user inputs, perform predefined actions, and provide answers based on the results of these actions. The contents of this revised Notebook are based on [A simple Python implementation of the ReAct pattern for LLMs](https://til.simonwillison.net/llms/python-react-pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce0457",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf73f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401c838",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "Load the environment variables from a .env file to access the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce624acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your OpenAI API Key: sk-ftrE5R1SUdZBr8XxRi3rtI4F5g2i47i67FfUv9AXmjT3BlbkFJqODP02vVsRNjuVbRKIfFInuuWKeXKv_SqGGoIUNokA\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"Your OpenAI API Key: {openai_api_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631f661",
   "metadata": {},
   "source": [
    "### Import OpenAI Library and Set API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7364ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenAI library and set API key\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Last snippet code that it works properly\n",
    "#import openai\n",
    "#import re\n",
    "#import httpx\n",
    "#import os\n",
    "#from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "#_ = load_dotenv(find_dotenv())  # This will find and load your .env file\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d21fb7",
   "metadata": {},
   "source": [
    "### Test the OpenAI API\n",
    "Test the OpenAI API with a simple completion query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Test the OpenAI API with a simple completion query\n",
    "# Correct OpenAI API usage\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "#chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8ba47",
   "metadata": {},
   "source": [
    "**Note**  The openai Python library doesn't expose a client object directly; instead, you interact with openai.ChatCompletion.create() for generating completions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bbd63",
   "metadata": {},
   "source": [
    "### Define the Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc485f36",
   "metadata": {},
   "source": [
    "In this section, we define `a Python class called Agent` that will serve as the core component of our ReAct agent. The Agent class is designed to handle user inputs, process them using the OpenAI API, and generate appropriate responses. The class includes methods for initializing the agent with a system prompt, handling user messages, and executing API calls to retrieve responses. This structure allows the agent to maintain a conversation flow, store context, and interact with predefined actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "# Define the Agent class\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        # Correct OpenAI API usage\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        #completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8df01e",
   "metadata": {},
   "source": [
    "**Note**: Fixing the Issue Use the OpenAI Library Directly: Replace client.chat.completions.create with the proper OpenAI library method: openai.ChatCompletion.create."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f931a",
   "metadata": {},
   "source": [
    "### Define the System Prompt for the Agent\n",
    "In this section, we define the system prompt that provides the initial context and instructions for the agent. The prompt outlines the `agent's operation loop, which includes phases such as Thought, Action, PAUSE, and Observation`. It also specifies the `available actions the agent can perform`, such as calculate and average_dog_weight, along with example sessions to illustrate how the agent should respond to user questions. This structured prompt helps guide the agent's behavior and ensures consistent and relevant interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "# Define the system prompt for the agent\n",
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ccc7f",
   "metadata": {},
   "source": [
    "### Define the Actions the Agent Can Perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902582f",
   "metadata": {},
   "source": [
    "In this section, we define `the specific actions that the agent is capable of executing`. Each action is implemented as a function, such as calculate for performing mathematical calculations and average_dog_weight for returning the average weight of a specified dog breed. These functions enable the agent to handle various user queries by executing the appropriate action and returning the corresponding result. The known_actions dictionary maps action names to their respective functions, allowing the agent to dynamically select and execute actions based on user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Define the actions the agent can perform\n",
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\": \n",
    "        return(\"Scottish Terriers average 20 lbs\")\n",
    "    elif name in \"Border Collie\":\n",
    "        return(\"a Border Collies average weight is 37 lbs\")\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return(\"a toy poodles average weight is 7 lbs\")\n",
    "    else:\n",
    "        return(\"An average dog weights 50 lbs\")\n",
    "\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda680eb",
   "metadata": {},
   "source": [
    "### Initialize the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543fa017",
   "metadata": {},
   "source": [
    "In this section, we initialize the Agent class with the system prompt defined earlier. This setup is crucial as it provides the initial context for the agent, enabling it to understand and respond to user inputs appropriately. By initializing the agent with the system prompt, we ensure that the agent starts with the necessary instructions and can maintain a coherent conversation flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Initialize the agent with the system prompt\n",
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28161b5c",
   "metadata": {},
   "source": [
    "**Note** :The functionality of the code remains the same regardless of the variable name you choose. In the above code, `abot` is simply a variable name chosen to instantiate the Agent class with the provided prompt. You can rename abot to any other valid Python variable name that makes sense in your context (e.g.:  agent, my_agent, or chatbot instead). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a38bbd3",
   "metadata": {},
   "source": [
    "### Run the Agent with a Test Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up the average weight of a Toy Poodle using the average_dog_weight action.\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "# Run the agent with a test question\n",
    "result = abot(\"How much does a toy poodle weigh?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f2700",
   "metadata": {},
   "source": [
    "### Run the average_dog_weight Action Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a toy poodles average weight is 7 lbs'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the average_dog_weight action directly\n",
    "result = average_dog_weight(\"Toy Poodle\")\n",
    "\n",
    "# Display the Result\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31867c09",
   "metadata": {},
   "source": [
    "#### Prepare the Next Prompt for the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Prepare the next prompt for the agent based on the observation\n",
    "next_prompt = \"Observation: {}\".format(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b065f",
   "metadata": {},
   "source": [
    "#### Run the Agent with the Next Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: A Toy Poodle weighs an average of 7 lbs.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab7778",
   "metadata": {},
   "source": [
    "#### Display the Agent's Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ada788",
   "metadata": {},
   "source": [
    "In this section, we print the messages stored within the agent to inspect the conversation history. This includes all interactions between the user and the agent, such as user inputs and the agent's responses. Displaying these messages helps to understand how the agent processes and responds to queries, and it can be useful for debugging and improving the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: I should look up the average weight of a Toy Poodle using the average_dog_weight action.\\nAction: average_dog_weight: Toy Poodle\\nPAUSE'},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Answer: A Toy Poodle weighs an average of 7 lbs.'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19e92b",
   "metadata": {},
   "source": [
    "#### Reinitialize the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512bd4a5",
   "metadata": {},
   "source": [
    "In this section, we reinitialize the Agent class to reset its state with the same system prompt. This step is useful for starting a new conversation or for resetting the agent's context. By reinitializing the agent, we ensure that it starts fresh without any previous messages or context, allowing for accurate and isolated testing of new interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Reinitialize the agent\n",
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070e885",
   "metadata": {},
   "source": [
    "#### Ask a New Question to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: I need to find the average weight of a Border Collie and a Scottish Terrier, then add them together to get the combined weight.\\nAction: average_dog_weight: Border Collie\\nPAUSE'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask a new question to the agent\n",
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "abot(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee863f2a",
   "metadata": {},
   "source": [
    "#### Prepare and Print the Next Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c3d8070-3f36-4cf0-a677-508e54359c8f",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: a Border Collies average weight is 37 lbs\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Border Collie\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcf696",
   "metadata": {},
   "source": [
    "#### Run the Agent with the Next Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action: average_dog_weight: Scottish Terrier\\nPAUSE'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5b2e5",
   "metadata": {},
   "source": [
    "#### Prepare and Print the Next Prompt for the Scottish Terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Scottish Terriers average 20 lbs\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Scottish Terrier\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4612a6",
   "metadata": {},
   "source": [
    "#### Run the Agent with the Next Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action: calculate: 37 + 20\\nPAUSE'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a833b",
   "metadata": {},
   "source": [
    "#### Prepare and Print the Next Prompt for Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 57\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(eval(\"37 + 20\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0bf3f",
   "metadata": {},
   "source": [
    "#### Run the Agent with the Next Prompt for Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The combined average weight of a Border Collie and a Scottish Terrier is 57 lbs.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e1153",
   "metadata": {},
   "source": [
    "#### Add a Loop for the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e2703",
   "metadata": {},
   "source": [
    "In this section, we add a loop to the agent's functionality to handle multiple iterations of user inputs and agent responses. This loop allows the agent to process a series of actions and observations in a structured manner. By defining a regular expression to match actions and creating a query function, we enable the agent to dynamically execute actions, observe results, and generate appropriate responses over several turns. This iterative process enhances the agent's capability to handle complex interactions and maintain context across multiple exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Michela\\AppData\\Local\\Temp\\ipykernel_4008\\3505718801.py:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action\n"
     ]
    }
   ],
   "source": [
    "# Define a regular expression to match actions\n",
    "action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {
    "height": 421
   },
   "outputs": [],
   "source": [
    "# Define a function to query the agent\n",
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the average weight of a Border Collie and a Scottish Terrier, then add them together to find their combined weight.\n",
      "Action: average_dog_weight: Border Collie\n",
      "PAUSE\n",
      " -- running average_dog_weight Border Collie\n",
      "Observation: a Border Collies average weight is 37 lbs\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      " -- running average_dog_weight Scottish Terrier\n",
      "Observation: Scottish Terriers average 20 lbs\n",
      "Thought: Now that I have the average weights of both the Border Collie and the Scottish Terrier, I can calculate their combined weight by adding these two values together.\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      " -- running calculate 37 + 20\n",
      "Observation: 57\n",
      "Answer: The combined average weight of a Border Collie and a Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "# Test the query function\n",
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b86a6-5e20-4252-b1d8-009b8318345a",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Conclusion \n",
    "In this notebook, we successfully built a simple ReAct agent from scratch using the OpenAI API. The agent can process user inputs, perform predefined actions, and provide answers based on the results of these actions. This demonstrates the potential of combining retrieval-augmented generation techniques with powerful language models to create intelligent agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af925917-b746-48c9-ac74-62fefbe5246c",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Extra Practice! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f73d77",
   "metadata": {},
   "source": [
    "- Example 1    \n",
    "\n",
    "Let's change the system agent of the prompt to ask to perform some calculation and returns the number using Python. To sum up, now the  available actions are:  \n",
    "`calculate:  \n",
    "e.g. calculate: 4 * 7 / 3  \n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary`  \n",
    "\n",
    "Fifteen * twenty five #   \n",
    "query(\"Fifteen * twenty five\")   \n",
    "Thought: The action required is a calculation   \n",
    "Action: calculate: 15 * 25   \n",
    "PAUSE  \n",
    " -- running calculate 15 * 25  \n",
    "Observation: 375  \n",
    "Answer: Fifteen times twenty five equals 375.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65ebba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should calculate the value using the calculate action.\n",
      "Action: calculate: 15 * 25\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt for the agent\n",
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop, you output an Answer.\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary.\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does 15 * 25 equal?\n",
    "Thought: I should calculate the value using the calculate action.\n",
    "Action: calculate: 15 * 25\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 375\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: 15 * 25 equals 375\n",
    "\"\"\".strip()\n",
    "\n",
    "# Define the Agent class (from the previous code)\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "            messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "# Define the actions the agent can perform\n",
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "known_actions = {\n",
    "    \"calculate\": calculate\n",
    "}\n",
    "\n",
    "# Initialize the agent with the system prompt\n",
    "agent = Agent(prompt)\n",
    "\n",
    "# Run the agent with a test question\n",
    "result = agent(\"How much does 15 * 25 equal?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3c552cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the calculation directly\n",
    "result = calculate(\"15 * 25\")\n",
    "\n",
    "# Display the Result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "620fb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the next prompt for the agent based on the observation(calculation)\n",
    "next_prompt = \"Observation: {}\".format(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b63f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 15 * 25 equals 375'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the next prompt\n",
    "agent(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1eae76",
   "metadata": {},
   "source": [
    "Test with another question related to a different calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c536fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize the agent \n",
    "agent = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dce28d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should calculate the value using the calculate action.\n",
      "Action: calculate: 4 * 7 / 3\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "# Run the agent with a new question\n",
    "result = agent(\"How much does 4 * 7 / 3 equal?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8ca02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.333333333333334"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the next prompt for the agent based on the observation(calculation)\n",
    "result = calculate(\"4 * 7 / 3\")\n",
    "\n",
    "# Display the Result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e825ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the next prompt for the agent based on the observation(calculation)\n",
    "next_prompt = \"Observation: {}\".format(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6033f7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 4 * 7 / 3 equals 9.333333333333334'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent (next_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
